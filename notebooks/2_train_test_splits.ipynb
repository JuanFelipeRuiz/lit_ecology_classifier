{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits of iamges to model\n",
    "This notebook presents how the splits for the models and the dataset version are handlet inside the plankton classifier pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1 Challenges and requiremnts of the split creation\n",
    "\n",
    "In order to ensure the reproducibility of old splits and to provide enough felxibility to try new split, a own modul was coded that could fulfill following points:\n",
    "\n",
    "- Reproducibility of old splits\n",
    "- Creation of new splits based on past data versions\n",
    "- Consideration of an OOD data set\n",
    "- Simple to implement extensions with own split methods\n",
    "\n",
    "\n",
    "This notebook shows how the split processing is handled, how to use it and how to register a new split version.\n",
    "\n",
    "### 1.1 Requires\n",
    "\n",
    "The notebook requires that all images are saved in the corresponding class folder, irrespective of the dataset version. Additionally, an overview data frame with the splits of the ZooLake version 1 and 2 must be provided. This can be achieved by utilising the notebook `1_data_set_overview.ipynb`, which is included in the notebook directory.\n",
    "\n",
    "### 1.2 Preparations\n",
    "\n",
    "The preparatios includes the navigating to the right dir level, installing the needed package and loading the overview dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 11:10:35,337 - root - DEBUG - Example debug message\n",
      "2024-12-20 11:10:35,338 - root - INFO - Example info message\n",
      "2024-12-20 11:10:35,338 - root - WARNING - Example warning message\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "# Clear existing handlers\n",
    "logger = logging.getLogger()\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Formatter and StreamHandler for the Notebook\n",
    "handler = logging.StreamHandler()\n",
    "\n",
    "# set format with file, line number, function name\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Example log messages\n",
    "logger.debug(\"Example debug message\")\n",
    "logger.info(\"Example info message\")\n",
    "logger.warning(\"Example warning message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing the current directory to the parent directory containing the setup.py file\n",
      "New current directory: c:\\Repos\\plankton_classifier, it will remain this working directory for the rest of the notebook\n",
      "Processing c:\\repos\\plankton_classifier\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (0.19.1)\n",
      "Requirement already satisfied: torchaudio in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.4.1)\n",
      "Requirement already satisfied: lightning in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.2.5)\n",
      "Requirement already satisfied: numpy in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.1.1)\n",
      "Requirement already satisfied: scipy in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (1.14.1)\n",
      "Requirement already satisfied: pandas in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (3.9.2)\n",
      "Requirement already satisfied: timm in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (1.0.9)\n",
      "Requirement already satisfied: safetensors in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (0.4.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (1.5.2)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (6.0.2)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (2024.9.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (0.11.7)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (24.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (1.4.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (4.12.2)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from torch->lit_ecology_classifier==2.0) (3.16.1)\n",
      "Requirement already satisfied: sympy in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from torch->lit_ecology_classifier==2.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from torch->lit_ecology_classifier==2.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from torch->lit_ecology_classifier==2.0) (3.1.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from pandas->lit_ecology_classifier==2.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from pandas->lit_ecology_classifier==2.0) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from scikit-learn->lit_ecology_classifier==2.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from scikit-learn->lit_ecology_classifier==2.0) (3.5.0)\n",
      "Requirement already satisfied: huggingface_hub in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from timm->lit_ecology_classifier==2.0) (0.25.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (3.10.6)\n",
      "Requirement already satisfied: setuptools in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning-utilities<2.0,>=0.8.0->lightning->lit_ecology_classifier==2.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lit_ecology_classifier==2.0) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning->lit_ecology_classifier==2.0) (0.4.6)\n",
      "Requirement already satisfied: requests in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from huggingface_hub->timm->lit_ecology_classifier==2.0) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from jinja2->torch->lit_ecology_classifier==2.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from sympy->torch->lit_ecology_classifier==2.0) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (1.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->lit_ecology_classifier==2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->lit_ecology_classifier==2.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->lit_ecology_classifier==2.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->lit_ecology_classifier==2.0) (2024.8.30)\n",
      "Building wheels for collected packages: lit_ecology_classifier\n",
      "  Building wheel for lit_ecology_classifier (pyproject.toml): started\n",
      "  Building wheel for lit_ecology_classifier (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for lit_ecology_classifier: filename=lit_ecology_classifier-2.0-py3-none-any.whl size=96269 sha256=8b7a8f7455f9971d47bcaa96c155fe367e921efef6bdfcf785a3846df667773c\n",
      "  Stored in directory: C:\\Users\\ruizjuan\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-wb0nk5r4\\wheels\\ef\\4e\\b8\\2be6c16208ad63911f0ceed2b4bee5a863a52ea77b22187903\n",
      "Successfully built lit_ecology_classifier\n",
      "Installing collected packages: lit_ecology_classifier\n",
      "  Attempting uninstall: lit_ecology_classifier\n",
      "    Found existing installation: lit_ecology_classifier 2.0\n",
      "    Uninstalling lit_ecology_classifier-2.0:\n",
      "      Successfully uninstalled lit_ecology_classifier-2.0\n",
      "Successfully installed lit_ecology_classifier-2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# preparations\n",
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def check_current_work_dir():\n",
    "    if not os.path.isfile(\"setup.py\") or  os.path.basename(os.getcwd()).endswith('notebooks'):\n",
    "        print(\"Changing the current directory to the parent directory containing the setup.py file\")\n",
    "\n",
    "        # move one folder up\n",
    "        os.chdir(\"..\")\n",
    "        print(f\"New current directory: {os.getcwd()}, it will remain this working directory for the rest of the notebook\")\n",
    "\n",
    "    if not os.path.isfile(\"setup.py\"):\n",
    "        raise Exception(\"setup.py not found in the current directory\")\n",
    "\n",
    "check_current_work_dir()\n",
    "\n",
    "check_current_work_dir()\n",
    "# installation of the package \n",
    "# \"%\"  makes the installation from a notebook cell out possible\n",
    "# and \".\" since the setup.py is in the current directory\n",
    "%pip install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>sha256</th>\n",
       "      <th>date</th>\n",
       "      <th>OOD_v2</th>\n",
       "      <th>version_1</th>\n",
       "      <th>version_2</th>\n",
       "      <th>train_v1</th>\n",
       "      <th>test_v1</th>\n",
       "      <th>val_v1</th>\n",
       "      <th>train_v2</th>\n",
       "      <th>test_v2</th>\n",
       "      <th>val_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570543372901157-3725350526242-...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...</td>\n",
       "      <td>2019-10-08 14:02:52+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570543374882008-3725352526408-...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...</td>\n",
       "      <td>2019-10-08 14:02:54+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472012505862-10217420880920...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...</td>\n",
       "      <td>2020-05-14 16:00:12+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472120505648-10217528889899...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...</td>\n",
       "      <td>2020-05-14 16:02:00+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472215513831-10217623897796...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>9cfb8f3f9d36cb50c32bedc72724092a7a01576ccb8529...</td>\n",
       "      <td>2020-05-14 16:03:35+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image          class  \\\n",
       "0  SPC-EAWAG-0P5X-1570543372901157-3725350526242-...  aphanizomenon   \n",
       "1  SPC-EAWAG-0P5X-1570543374882008-3725352526408-...  aphanizomenon   \n",
       "2  SPC-EAWAG-0P5X-1589472012505862-10217420880920...  aphanizomenon   \n",
       "3  SPC-EAWAG-0P5X-1589472120505648-10217528889899...  aphanizomenon   \n",
       "4  SPC-EAWAG-0P5X-1589472215513831-10217623897796...  aphanizomenon   \n",
       "\n",
       "                                              sha256  \\\n",
       "0  6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...   \n",
       "1  09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...   \n",
       "2  1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...   \n",
       "3  f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...   \n",
       "4  9cfb8f3f9d36cb50c32bedc72724092a7a01576ccb8529...   \n",
       "\n",
       "                        date  OOD_v2  version_1  version_2  train_v1  test_v1  \\\n",
       "0  2019-10-08 14:02:52+00:00   False       True       True      True    False   \n",
       "1  2019-10-08 14:02:54+00:00   False       True       True      True    False   \n",
       "2  2020-05-14 16:00:12+00:00   False       True       True      True    False   \n",
       "3  2020-05-14 16:02:00+00:00   False       True       True      True    False   \n",
       "4  2020-05-14 16:03:35+00:00   False       True       True     False    False   \n",
       "\n",
       "   val_v1  train_v2  test_v2  val_v2  \n",
       "0   False      True    False   False  \n",
       "1   False     False     True   False  \n",
       "2   False      True    False   False  \n",
       "3   False      True    False   False  \n",
       "4    True      True    False   False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the overview data\n",
    "path = os.path.join(\"data\", \"interim\",  \"overview.csv\")\n",
    "df = pd.read_csv( filepath_or_buffer= path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>sha256</th>\n",
       "      <th>split</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29640</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624734366033156-29241721188723...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>f918287e56745c04bda26e4e41c7410829460f1e00c9b8...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29641</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624662155318571-29169511575069...</td>\n",
       "      <td>asplanchna</td>\n",
       "      <td>a09365d3b45b8d69976b0796f885d51c8763b7e035def9...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29642</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624662157341137-29169513575235...</td>\n",
       "      <td>asplanchna</td>\n",
       "      <td>a4ca7d1c4daac22313245706347e3544fa90722273472c...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29643</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624662354355777-29169710591612...</td>\n",
       "      <td>asplanchna</td>\n",
       "      <td>55df99360fdc74e9485846e4d836232df919e832e23a1e...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29644</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624662437359090-29169793598512...</td>\n",
       "      <td>asplanchna</td>\n",
       "      <td>1610bc0981eb9b8543fa0a4e8b6afaa1a22788b6fdbcbc...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image          class  \\\n",
       "29640  SPC-EAWAG-0P5X-1624734366033156-29241721188723...  aphanizomenon   \n",
       "29641  SPC-EAWAG-0P5X-1624662155318571-29169511575069...     asplanchna   \n",
       "29642  SPC-EAWAG-0P5X-1624662157341137-29169513575235...     asplanchna   \n",
       "29643  SPC-EAWAG-0P5X-1624662354355777-29169710591612...     asplanchna   \n",
       "29644  SPC-EAWAG-0P5X-1624662437359090-29169793598512...     asplanchna   \n",
       "\n",
       "                                                  sha256 split version  \n",
       "29640  f918287e56745c04bda26e4e41c7410829460f1e00c9b8...   OOD       2  \n",
       "29641  a09365d3b45b8d69976b0796f885d51c8763b7e035def9...   OOD       2  \n",
       "29642  a4ca7d1c4daac22313245706347e3544fa90722273472c...   OOD       2  \n",
       "29643  55df99360fdc74e9485846e4d836232df919e832e23a1e...   OOD       2  \n",
       "29644  1610bc0981eb9b8543fa0a4e8b6afaa1a22788b6fdbcbc...   OOD       2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation to a tidy format\n",
    "df = df.filter(regex=\"train|test|val|image|class|sha256|OOD\")\n",
    "\n",
    "# Melt test, train, and val columns into one column per row and version\n",
    "df_melted = df.filter(regex=\"v1|v2|image|class|sha256\").melt(\n",
    "    id_vars=['image', 'class', 'sha256'],\n",
    "    var_name='split'\n",
    ")\n",
    "\n",
    "# Extract 'version' and 'split' from the 'split' column using vectorized string methods\n",
    "df_melted[\"version\"] = df_melted[\"split\"].str.split('_').str[1]\n",
    "df_melted[\"split\"] = df_melted[\"split\"].str.split('_').str[0]\n",
    "\n",
    "# Keep only rows where 'value' is 1\n",
    "df_melted = df_melted[df_melted['value'] == 1]\n",
    "\n",
    "# Replace version labels for consistency\n",
    "df_melted[\"version\"] = df_melted[\"version\"].replace({\"v1\": \"1\", \"v2\": \"2\"})\n",
    "\n",
    "# Drop the 'value' column as it's no longer needed\n",
    "df_melted = df_melted.drop(columns=\"value\")\n",
    "\n",
    "# Display the first few rows of the transformed dataframe\n",
    "df_melted.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2 Split Overview\n",
    "\n",
    "The split overview was created with the ambition to keep informations and track of the used split. It includes following columns:\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\n",
    "\\begin{array}{c}\n",
    "\\textbf{Description of the split overview dataframe}\\\\\n",
    "\\newline\n",
    "\\begin{array}{|l|l|}\n",
    "\\hline\n",
    "\\textbf{Column name} & \\textbf{Description} \\\\\n",
    "\\hline\n",
    "\\text{dataset version} & \\text{Version of the Dataset used for the split} \\\\\n",
    "\\text{OOD} & \\text{OOD version included in the split} \\\\\n",
    "\\text{split strategy} & \\text{Used split strategy} \\\\\n",
    "\\text{combined split hash} & \\text{Hash value to identfiy and check the split} \\\\\n",
    "\\text{Description} & \\text{Place to add a short description of the split} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\n",
    "$$\n",
    "\n",
    "\\\n",
    "The current status of the split overview can be found in the folder \"interim\\UsedSplit\\\". Nevertheless, the intention is to store the overview split in a database in the near future.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_version</th>\n",
       "      <th>OOD</th>\n",
       "      <th>split_strategy</th>\n",
       "      <th>filter_strategy</th>\n",
       "      <th>combined_split_hash</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...</td>\n",
       "      <td>Split used for Deep Learning Classification of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OOD_2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ac1342e84ca156574ef657e342945eeee398dc01c0563...</td>\n",
       "      <td>Split used for Producing Plankton Classifiers ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_version     OOD split_strategy filter_strategy  \\\n",
       "0               1                Unknown  PlanktonFilter   \n",
       "1               2   OOD_2        Unknown  PlanktonFilter   \n",
       "\n",
       "                                 combined_split_hash  \\\n",
       "0  7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...   \n",
       "1  7ac1342e84ca156574ef657e342945eeee398dc01c0563...   \n",
       "\n",
       "                                         description  \n",
       "0  Split used for Deep Learning Classification of...  \n",
       "1  Split used for Producing Plankton Classifiers ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading of the split overview \n",
    "path = os.path.join(\"data\", \"interim\", \"UsedSplits\", \"split_overview.csv\")\n",
    "\n",
    "types = {\n",
    "    \"dataset_version\": \"str\",\n",
    "    \"OOD\": \"str\",\n",
    "    \"split_strategy\": \"str\",\n",
    "    \"combined_split_hash\": \"str\",\n",
    "    \"fescription\": \"str\"\n",
    "}\n",
    "\n",
    "split_overview = pd.read_csv(filepath_or_buffer= path, index_col=False, dtype=types)\n",
    "split_overview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Split hashes and comnined split hash\n",
    "\n",
    "In order to not only store information but also to verify whether the reconstructed splits align with the original ones,  the property of hashing was again utilised based on the  images hashesh.\n",
    "\n",
    "### 3.1 Split hashes\n",
    "\n",
    "The split hashes are calculated based on a sorted join of each hash within each unique value of the column \"split\".  This is shown for the first Zoolake version below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': '3dc0e5aadb042c37d8e52908b23c9b0af83e2497109e7e1c5a25d2b65c5e14be',\n",
       " 'train': 'bc9bb5d05fbdd28547737c9953d10fa3f584e9a832dc7e2c75d1b6751f5a2024',\n",
       " 'val': '1d24484776f9579e8bdd468c884dd4df15eb4429ea89d136fed636245d8c49e9'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of the split hashes \n",
    "\n",
    "from lit_ecology_classifier.helpers.hashing import HashGenerator\n",
    "\n",
    "# filter to calculate the hashes for the first version\n",
    "df_v1 = df_melted[df_melted[\"version\"] == \"1\"]\n",
    "\n",
    "# generate the hashes\n",
    "hashes_v1 = HashGenerator().generate_hash_dict_from_split(df_v1, col_to_hash =\"sha256\", group_by_col= \"split\")\n",
    "\n",
    "hashes_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated by the output, the values of the dictionary represent the calculated hash value for each split. This makes it possible to find out if each reproduced split  correspond to the original one.\n",
    "\n",
    "### 3.1 Combined split hashes\n",
    "A value per split presents the disadvantage of complicating a direct comparison of whether the entire split is identical. For this reason, the individual hash values are sorted and hashed again. This leads to the loss of knwoing wich hash differs now. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214c00e80c52845c5eaed'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_hash = HashGenerator().sha256_from_list(hashes_v1.values())    \n",
    "combined_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilisation of the images and split hashes permits the theoretical identification down to the pixel value whether the splits are identical or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 SplitProcessor\n",
    "\n",
    "In order to fulfil the necessary requirements to create and recreate old splits, the class `SplitProcessor` was implemented. The Split Processor provides the main functionalities to manage all aspects of the data splitting process, including the checking of existing splits, the creation of new splits and the execution of the image copying. \n",
    "\n",
    "The implementation of the split processor is object-oriented, employing polymorphism for the split strategy and inheritance of the `base_image_mover.py` functionalities for the copying of the images. \n",
    "\n",
    "At the momement, the created splits and overview are stored inside the file folder `interim\\UsedSplit\\`  However, it is intended that this will be replaced in the near future with a database.\n",
    "\n",
    "### 4.1 Attributes\n",
    "\n",
    "xyz\n",
    "\n",
    "\n",
    "### 4.2 How to use\n",
    "\n",
    "\n",
    "#### 4.2.1 Recreation of splits \n",
    "\n",
    "To recreate a used split the split strategy, dataset version and OOD Version need to be defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 12-13: truncated \\UXXXXXXXX escape (4057599675.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    split_folder = \"data\\interim\\UsedSplits\",\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 12-13: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# recreation of a split\n",
    "from lit_ecology_classifier.splitting.split import SplitProcessor\n",
    "\n",
    "split_processor = SplitProcessor(\n",
    "                                split_overview = split_overview,\n",
    "                                split_folder = r\"data\\interim\\UsedSplits\",\n",
    "                                image_overview= \"data\\interim\\overview.csv\",\n",
    "                                split_strategy= 'Unknown',\n",
    "                                filter_strategy= 'PlanktonFilter'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>sha256</th>\n",
       "      <th>split</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570543372901157-3725350526242-...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570543374882008-3725352526408-...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472012505862-10217420880920...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472120505648-10217528889899...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472588541825-10217996928805...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>5ca3294d8df48501fd83731564c93442fedd1002c1b6f4...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18079</th>\n",
       "      <td>SPC-EAWAG-0P5X-1563195834608473-10101205289100...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>225a67488e4bab2ece16cf9fc2c013524608601c7b2350...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18080</th>\n",
       "      <td>SPC-EAWAG-0P5X-1563196067636305-10101438308470...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>64882fcbfbc4aff5835c4cd21e16a0201c1a12a51c4d98...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18081</th>\n",
       "      <td>SPC-EAWAG-0P5X-1575370922015129-8552825698030-...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>240ef901638276c790bb83c791b48eb04ecd09b53bcc43...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18082</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589537321913540-10282729292872...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>f5edd8827d77807a30626961e984e3536f66fe30d2b0c7...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18083</th>\n",
       "      <td>SPC-EAWAG-0P5X-1591675305662922-12420681042323...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>459b730831e5bbe33f689d783b79b8a2343a156934db0a...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18084 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  \\\n",
       "0      SPC-EAWAG-0P5X-1570543372901157-3725350526242-...   \n",
       "1      SPC-EAWAG-0P5X-1570543374882008-3725352526408-...   \n",
       "2      SPC-EAWAG-0P5X-1589472012505862-10217420880920...   \n",
       "3      SPC-EAWAG-0P5X-1589472120505648-10217528889899...   \n",
       "4      SPC-EAWAG-0P5X-1589472588541825-10217996928805...   \n",
       "...                                                  ...   \n",
       "18079  SPC-EAWAG-0P5X-1563195834608473-10101205289100...   \n",
       "18080  SPC-EAWAG-0P5X-1563196067636305-10101438308470...   \n",
       "18081  SPC-EAWAG-0P5X-1575370922015129-8552825698030-...   \n",
       "18082  SPC-EAWAG-0P5X-1589537321913540-10282729292872...   \n",
       "18083  SPC-EAWAG-0P5X-1591675305662922-12420681042323...   \n",
       "\n",
       "                      class  \\\n",
       "0             aphanizomenon   \n",
       "1             aphanizomenon   \n",
       "2             aphanizomenon   \n",
       "3             aphanizomenon   \n",
       "4             aphanizomenon   \n",
       "...                     ...   \n",
       "18079  keratella_cochlearis   \n",
       "18080  keratella_cochlearis   \n",
       "18081  keratella_cochlearis   \n",
       "18082  keratella_cochlearis   \n",
       "18083  keratella_cochlearis   \n",
       "\n",
       "                                                  sha256  split  version  \n",
       "0      6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...  train        1  \n",
       "1      09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...  train        1  \n",
       "2      1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...  train        1  \n",
       "3      f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...  train        1  \n",
       "4      5ca3294d8df48501fd83731564c93442fedd1002c1b6f4...  train        1  \n",
       "...                                                  ...    ...      ...  \n",
       "18079  225a67488e4bab2ece16cf9fc2c013524608601c7b2350...    val        1  \n",
       "18080  64882fcbfbc4aff5835c4cd21e16a0201c1a12a51c4d98...    val        1  \n",
       "18081  240ef901638276c790bb83c791b48eb04ecd09b53bcc43...    val        1  \n",
       "18082  f5edd8827d77807a30626961e984e3536f66fe30d2b0c7...    val        1  \n",
       "18083  459b730831e5bbe33f689d783b79b8a2343a156934db0a...    val        1  \n",
       "\n",
       "[18084 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"split_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Use of build in split strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - DEBUG - Image overview column types: image        object\n",
      "class        object\n",
      "sha256       object\n",
      "date         object\n",
      "OOD_v2         bool\n",
      "version_1      bool\n",
      "version_2      bool\n",
      "train_v1       bool\n",
      "test_v1        bool\n",
      "val_v1         bool\n",
      "train_v2       bool\n",
      "test_v2        bool\n",
      "val_v2         bool\n",
      "dtype: object\n",
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - DEBUG - Class name: Stratified\n",
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - DEBUG - Splitstrategie: Stratified\n",
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - DEBUG - Filterstrategie: PlanktonFilter\n",
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - DEBUG - Class name: Stratified\n",
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - DEBUG - Existing split:Empty DataFrame\n",
      "Columns: [dataset_version, OOD, split_strategy, filter_strategy, combined_split_hash, description]\n",
      "Index: []\n",
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - INFO - No existing split found with the given strategies, creating new split.\n",
      "2024-12-16 11:09:53,216 - lit_ecology_classifier.splitting.split - DEBUG - Importing the modul lit_ecology_classifier.splitting.split_strategies.Stratified\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.splitting.split - DEBUG - Importing the modul lit_ecology_classifier.splitting.filtering.PlanktonFilter\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.splitting.split - DEBUG - Starting filtering of the image overview.\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.helpers.filter - DEBUG - Filtering the dataframe based on the dataset versions: []\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.helpers.filter - DEBUG - No dataset version provided, returning the original dataframe\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.helpers.filter - DEBUG - Filtering the OOD images from the dataframe out.\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.helpers.filter - DEBUG - No OOD defined, not filterig based on the OOD images.\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.splitting.split - DEBUG - Filtering of the image overview completed.\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.helpers.filter - DEBUG - Creating the class mapping based on the unique class labels.\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.helpers.filter - DEBUG - Unique class labels found: ['aphanizomenon' 'asplanchna' 'asterionella' 'bosmina' 'brachionus'\n",
      " 'ceratium' 'chaoborus' 'conochilus' 'copepod_skins' 'cyclops' 'daphnia'\n",
      " 'daphnia_skins' 'diaphanosoma' 'diatom_chain' 'dinobryon' 'dirt'\n",
      " 'eudiaptomus' 'filament' 'fish' 'fragilaria' 'hydra' 'kellicottia'\n",
      " 'keratella_cochlearis' 'keratella_quadrata' 'leptodora' 'maybe_cyano'\n",
      " 'nauplius' 'paradileptus' 'polyarthra' 'rotifers' 'synchaeta'\n",
      " 'trichocerca' 'unknown' 'unknown_plankton' 'uroglena' 'collotheca']\n",
      "2024-12-16 11:09:53,646 - root - INFO - Classes to keep based on defined priority classes, if emtpy no prio are set:[] \n",
      "             Classes to keep based on defined rest classes. If empty, no class are filtered out: []\n",
      "2024-12-16 11:09:53,646 - lit_ecology_classifier.splitting.split - DEBUG - Class map: {'aphanizomenon': 1, 'asplanchna': 2, 'asterionella': 3, 'bosmina': 4, 'brachionus': 5, 'ceratium': 6, 'chaoborus': 7, 'collotheca': 8, 'conochilus': 9, 'copepod_skins': 10, 'cyclops': 11, 'daphnia': 12, 'daphnia_skins': 13, 'diaphanosoma': 14, 'diatom_chain': 15, 'dinobryon': 16, 'dirt': 17, 'eudiaptomus': 18, 'filament': 19, 'fish': 20, 'fragilaria': 21, 'hydra': 22, 'kellicottia': 23, 'keratella_cochlearis': 24, 'keratella_quadrata': 25, 'leptodora': 26, 'maybe_cyano': 27, 'nauplius': 28, 'paradileptus': 29, 'polyarthra': 30, 'rotifers': 31, 'synchaeta': 32, 'trichocerca': 33, 'unknown': 34, 'unknown_plankton': 35, 'uroglena': 36}\n",
      "2024-12-16 11:09:53,663 - lit_ecology_classifier.splitting.split - DEBUG - Filtering of the image overview completed, starting splitting.\n",
      "2024-12-16 11:09:53,663 - lit_ecology_classifier.splitting.split_strategies.stratified - INFO - Performing stratified split. Shape of data:(39162, 14)\n",
      "2024-12-16 11:09:53,673 - lit_ecology_classifier.splitting.split - INFO - Splitted data successfully with Stratified\n",
      "2024-12-16 11:09:53,680 - lit_ecology_classifier.splitting.split - DEBUG - Columns filtered dataframe: Index(['image', 'class', 'sha256', 'date', 'OOD_v2', 'version_1', 'version_2',\n",
      "       'train_v1', 'test_v1', 'val_v1', 'train_v2', 'test_v2', 'val_v2',\n",
      "       'class_map'],\n",
      "      dtype='object')\n",
      "2024-12-16 11:09:53,696 - lit_ecology_classifier.splitting.split - DEBUG - Starting generation of hashes. Split_Df columns: Index(['image', 'class_map', 'split', 'sha256'], dtype='object')\n",
      "2024-12-16 11:09:53,697 - lit_ecology_classifier.splitting.split - DEBUG - Finished generation of hashes.\n",
      "2024-12-16 11:09:53,697 - lit_ecology_classifier.splitting.split - INFO - Split overview updated.\n"
     ]
    }
   ],
   "source": [
    "split_processor = SplitProcessor(\n",
    "                                split_strategy= 'Stratified',\n",
    "                                filter_strategy= 'PlanktonFilter',\n",
    "                                split_overview = split_overview, \n",
    "                                image_overview= \"data\\interim\\overview.csv\",\n",
    "                                filter_args= {\"dataset_version\":\"1\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_version</th>\n",
       "      <th>OOD</th>\n",
       "      <th>split_strategy</th>\n",
       "      <th>filter_strategy</th>\n",
       "      <th>combined_split_hash</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...</td>\n",
       "      <td>Split used for Deep Learning Classification of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OOD_2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ac1342e84ca156574ef657e342945eeee398dc01c0563...</td>\n",
       "      <td>Split used for Producing Plankton Classifiers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stratified</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>eca71e33b09d856f6a8d2b9c2ecb8fbec2d335b640349c...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_version     OOD split_strategy filter_strategy  \\\n",
       "0               1                Unknown  PlanktonFilter   \n",
       "1               2   OOD_2        Unknown  PlanktonFilter   \n",
       "2             NaN     NaN     Stratified  PlanktonFilter   \n",
       "\n",
       "                                 combined_split_hash  \\\n",
       "0  7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...   \n",
       "1  7ac1342e84ca156574ef657e342945eeee398dc01c0563...   \n",
       "2  eca71e33b09d856f6a8d2b9c2ecb8fbec2d335b640349c...   \n",
       "\n",
       "                                         description  \n",
       "0  Split used for Deep Learning Classification of...  \n",
       "1  Split used for Producing Plankton Classifiers ...  \n",
       "2                                               None  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"split_overview_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class_map</th>\n",
       "      <th>split</th>\n",
       "      <th>sha256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570496498567211-3678476912301-...</td>\n",
       "      <td>27</td>\n",
       "      <td>train</td>\n",
       "      <td>e08bae075ae69dcde0bf83929c8fff5b3bac78e5a91e86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPC-EAWAG-0P5X-1602248934427170-6756627266623-...</td>\n",
       "      <td>34</td>\n",
       "      <td>train</td>\n",
       "      <td>1e1e28cad3f2b9f419ff564df6c3151fc3c4d3c0cd04ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPC-EAWAG-0P5X-1657771518040069-62278380186028...</td>\n",
       "      <td>25</td>\n",
       "      <td>train</td>\n",
       "      <td>778882d5c100a75e52db1b40b34057f7cff661cca5665f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPC-EAWAG-0P5X-1659985235615601-64492066900435...</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "      <td>8262751c828fdb1450702399b2a7266037c8615079a34e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPC-EAWAG-0P5X-1656770957698475-61277833504801...</td>\n",
       "      <td>21</td>\n",
       "      <td>train</td>\n",
       "      <td>9e99e17ed206341d0bdf019667c6b9d1fcf1bb75338b99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39437</th>\n",
       "      <td>SPC-EAWAG-0P5X-1637899349834501-42406507666460...</td>\n",
       "      <td>19</td>\n",
       "      <td>test</td>\n",
       "      <td>c14264dd6af57153fdba959e5e1eb53a0ae0cca4d7d52f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39438</th>\n",
       "      <td>SPC-EAWAG-0P5X-1656907704320527-61414578280829...</td>\n",
       "      <td>28</td>\n",
       "      <td>test</td>\n",
       "      <td>8be1c0bab769b1f241dc461e916df1d963dfd1ec7c567e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39439</th>\n",
       "      <td>SPC-EAWAG-0P5X-1590653329775022-11398720303487...</td>\n",
       "      <td>16</td>\n",
       "      <td>test</td>\n",
       "      <td>a02247a0645fd405168c8b239575d137ba489dd74c451f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39440</th>\n",
       "      <td>SPC-EAWAG-0P5X-1659812915599649-64319749241096...</td>\n",
       "      <td>20</td>\n",
       "      <td>test</td>\n",
       "      <td>2098b9b552be5af76dc1fed870db37e338bfa096ffa48a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39441</th>\n",
       "      <td>SPC-EAWAG-0P5X-1529021641835794-735637579197-0...</td>\n",
       "      <td>16</td>\n",
       "      <td>test</td>\n",
       "      <td>17028e7c117a35584f940b42009d7b778b17ce3bf33ba5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39442 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  class_map  split  \\\n",
       "0      SPC-EAWAG-0P5X-1570496498567211-3678476912301-...         27  train   \n",
       "1      SPC-EAWAG-0P5X-1602248934427170-6756627266623-...         34  train   \n",
       "2      SPC-EAWAG-0P5X-1657771518040069-62278380186028...         25  train   \n",
       "3      SPC-EAWAG-0P5X-1659985235615601-64492066900435...         35  train   \n",
       "4      SPC-EAWAG-0P5X-1656770957698475-61277833504801...         21  train   \n",
       "...                                                  ...        ...    ...   \n",
       "39437  SPC-EAWAG-0P5X-1637899349834501-42406507666460...         19   test   \n",
       "39438  SPC-EAWAG-0P5X-1656907704320527-61414578280829...         28   test   \n",
       "39439  SPC-EAWAG-0P5X-1590653329775022-11398720303487...         16   test   \n",
       "39440  SPC-EAWAG-0P5X-1659812915599649-64319749241096...         20   test   \n",
       "39441  SPC-EAWAG-0P5X-1529021641835794-735637579197-0...         16   test   \n",
       "\n",
       "                                                  sha256  \n",
       "0      e08bae075ae69dcde0bf83929c8fff5b3bac78e5a91e86...  \n",
       "1      1e1e28cad3f2b9f419ff564df6c3151fc3c4d3c0cd04ba...  \n",
       "2      778882d5c100a75e52db1b40b34057f7cff661cca5665f...  \n",
       "3      8262751c828fdb1450702399b2a7266037c8615079a34e...  \n",
       "4      9e99e17ed206341d0bdf019667c6b9d1fcf1bb75338b99...  \n",
       "...                                                  ...  \n",
       "39437  c14264dd6af57153fdba959e5e1eb53a0ae0cca4d7d52f...  \n",
       "39438  8be1c0bab769b1f241dc461e916df1d963dfd1ec7c567e...  \n",
       "39439  a02247a0645fd405168c8b239575d137ba489dd74c451f...  \n",
       "39440  2098b9b552be5af76dc1fed870db37e338bfa096ffa48a...  \n",
       "39441  17028e7c117a35584f940b42009d7b778b17ce3bf33ba5...  \n",
       "\n",
       "[39442 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"split_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aphanizomenon': 1,\n",
       " 'asplanchna': 2,\n",
       " 'asterionella': 3,\n",
       " 'bosmina': 4,\n",
       " 'brachionus': 5,\n",
       " 'ceratium': 6,\n",
       " 'chaoborus': 7,\n",
       " 'collotheca': 8,\n",
       " 'conochilus': 9,\n",
       " 'copepod_skins': 10,\n",
       " 'cyclops': 11,\n",
       " 'daphnia': 12,\n",
       " 'daphnia_skins': 13,\n",
       " 'diaphanosoma': 14,\n",
       " 'diatom_chain': 15,\n",
       " 'dinobryon': 16,\n",
       " 'dirt': 17,\n",
       " 'eudiaptomus': 18,\n",
       " 'filament': 19,\n",
       " 'fish': 20,\n",
       " 'fragilaria': 21,\n",
       " 'hydra': 22,\n",
       " 'kellicottia': 23,\n",
       " 'keratella_cochlearis': 24,\n",
       " 'keratella_quadrata': 25,\n",
       " 'leptodora': 26,\n",
       " 'maybe_cyano': 27,\n",
       " 'nauplius': 28,\n",
       " 'paradileptus': 29,\n",
       " 'polyarthra': 30,\n",
       " 'rotifers': 31,\n",
       " 'synchaeta': 32,\n",
       " 'trichocerca': 33,\n",
       " 'unknown': 34,\n",
       " 'unknown_plankton': 35,\n",
       " 'uroglena': 36}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"class_map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useage with own splot strategie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lit_ecology_classifier.splitting.split_strategies.base_split_strategy import BaseSplitStrategy\n",
    "\n",
    "class ExampleSplitProcessor(BaseSplitStrategy):\n",
    "\n",
    "    def perform_split(self, df, y_col = \"class_map\"):\n",
    "        X = df[\"image\"]\n",
    "        y = df[y_col]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        return {\n",
    "            \"train\": [X_train,y_train],\n",
    "            \"test\": [X_test, y_test]    \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 11:09:53,811 - lit_ecology_classifier.splitting.split - DEBUG - Image overview column types: image        object\n",
      "class        object\n",
      "sha256       object\n",
      "date         object\n",
      "OOD_v2         bool\n",
      "version_1      bool\n",
      "version_2      bool\n",
      "train_v1       bool\n",
      "test_v1        bool\n",
      "val_v1         bool\n",
      "train_v2       bool\n",
      "test_v2        bool\n",
      "val_v2         bool\n",
      "dtype: object\n",
      "2024-12-16 11:09:53,812 - lit_ecology_classifier.splitting.split - DEBUG - Class name: ExampleSplitProcessor\n",
      "2024-12-16 11:09:53,812 - lit_ecology_classifier.splitting.split - DEBUG - Splitstrategie: ExampleSplitProcessor\n",
      "2024-12-16 11:09:53,813 - lit_ecology_classifier.splitting.split - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-16 11:09:53,814 - lit_ecology_classifier.splitting.split - DEBUG - Filterstrategie: PlanktonFilter\n",
      "2024-12-16 11:09:53,814 - lit_ecology_classifier.splitting.split - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-16 11:09:53,815 - lit_ecology_classifier.splitting.split - DEBUG - Class name: ExampleSplitProcessor\n",
      "2024-12-16 11:09:53,816 - lit_ecology_classifier.splitting.split - DEBUG - Existing split:Empty DataFrame\n",
      "Columns: [dataset_version, OOD, split_strategy, filter_strategy, combined_split_hash, description]\n",
      "Index: []\n",
      "2024-12-16 11:09:53,817 - lit_ecology_classifier.splitting.split - INFO - No existing split found with the given strategies, creating new split.\n",
      "2024-12-16 11:09:53,817 - lit_ecology_classifier.splitting.split - DEBUG - Importing the modul lit_ecology_classifier.splitting.filtering.PlanktonFilter\n",
      "2024-12-16 11:09:53,818 - lit_ecology_classifier.splitting.split - DEBUG - Starting filtering of the image overview.\n",
      "2024-12-16 11:09:53,818 - lit_ecology_classifier.helpers.filter - DEBUG - Filtering the dataframe based on the dataset versions: []\n",
      "2024-12-16 11:09:53,818 - lit_ecology_classifier.helpers.filter - DEBUG - No dataset version provided, returning the original dataframe\n",
      "2024-12-16 11:09:53,819 - lit_ecology_classifier.helpers.filter - DEBUG - Filtering the OOD images from the dataframe out.\n",
      "2024-12-16 11:09:53,819 - lit_ecology_classifier.helpers.filter - DEBUG - No OOD defined, not filterig based on the OOD images.\n",
      "2024-12-16 11:09:53,820 - lit_ecology_classifier.splitting.split - DEBUG - Filtering of the image overview completed.\n",
      "2024-12-16 11:09:53,820 - lit_ecology_classifier.helpers.filter - DEBUG - Creating the class mapping based on the unique class labels.\n",
      "2024-12-16 11:09:53,821 - lit_ecology_classifier.helpers.filter - DEBUG - Unique class labels found: ['aphanizomenon' 'asplanchna' 'asterionella' 'bosmina' 'brachionus'\n",
      " 'ceratium' 'chaoborus' 'conochilus' 'copepod_skins' 'cyclops' 'daphnia'\n",
      " 'daphnia_skins' 'diaphanosoma' 'diatom_chain' 'dinobryon' 'dirt'\n",
      " 'eudiaptomus' 'filament' 'fish' 'fragilaria' 'hydra' 'kellicottia'\n",
      " 'keratella_cochlearis' 'keratella_quadrata' 'leptodora' 'maybe_cyano'\n",
      " 'nauplius' 'paradileptus' 'polyarthra' 'rotifers' 'synchaeta'\n",
      " 'trichocerca' 'unknown' 'unknown_plankton' 'uroglena' 'collotheca']\n",
      "2024-12-16 11:09:53,822 - root - INFO - Classes to keep based on defined priority classes, if emtpy no prio are set:[] \n",
      "             Classes to keep based on defined rest classes. If empty, no class are filtered out: []\n",
      "2024-12-16 11:09:53,822 - lit_ecology_classifier.splitting.split - DEBUG - Class map: {'aphanizomenon': 1, 'asplanchna': 2, 'asterionella': 3, 'bosmina': 4, 'brachionus': 5, 'ceratium': 6, 'chaoborus': 7, 'collotheca': 8, 'conochilus': 9, 'copepod_skins': 10, 'cyclops': 11, 'daphnia': 12, 'daphnia_skins': 13, 'diaphanosoma': 14, 'diatom_chain': 15, 'dinobryon': 16, 'dirt': 17, 'eudiaptomus': 18, 'filament': 19, 'fish': 20, 'fragilaria': 21, 'hydra': 22, 'kellicottia': 23, 'keratella_cochlearis': 24, 'keratella_quadrata': 25, 'leptodora': 26, 'maybe_cyano': 27, 'nauplius': 28, 'paradileptus': 29, 'polyarthra': 30, 'rotifers': 31, 'synchaeta': 32, 'trichocerca': 33, 'unknown': 34, 'unknown_plankton': 35, 'uroglena': 36}\n",
      "2024-12-16 11:09:53,826 - lit_ecology_classifier.splitting.split - DEBUG - Filtering of the image overview completed, starting splitting.\n",
      "2024-12-16 11:09:53,830 - lit_ecology_classifier.splitting.split - INFO - Splitted data successfully with ExampleSplitProcessor\n",
      "2024-12-16 11:09:53,830 - lit_ecology_classifier.splitting.split - DEBUG - Columns filtered dataframe: Index(['image', 'class', 'sha256', 'date', 'OOD_v2', 'version_1', 'version_2',\n",
      "       'train_v1', 'test_v1', 'val_v1', 'train_v2', 'test_v2', 'val_v2',\n",
      "       'class_map'],\n",
      "      dtype='object')\n",
      "2024-12-16 11:09:53,847 - lit_ecology_classifier.splitting.split - DEBUG - Starting generation of hashes. Split_Df columns: Index(['image', 'class_map', 'split', 'sha256'], dtype='object')\n",
      "2024-12-16 11:09:53,864 - lit_ecology_classifier.splitting.split - DEBUG - Finished generation of hashes.\n",
      "2024-12-16 11:09:53,866 - lit_ecology_classifier.splitting.split - INFO - Split overview updated.\n"
     ]
    }
   ],
   "source": [
    "split_processor = SplitProcessor(split_strategy= ExampleSplitProcessor(),\n",
    "                                 filter_strategy= 'PlanktonFilter',\n",
    "                                 split_overview = split_overview, \n",
    "                                 image_overview= \"data\\interim\\overview.csv\",\n",
    "                                 filter_args= {\"dataset_version\":\"2\"})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_version</th>\n",
       "      <th>OOD</th>\n",
       "      <th>split_strategy</th>\n",
       "      <th>filter_strategy</th>\n",
       "      <th>combined_split_hash</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...</td>\n",
       "      <td>Split used for Deep Learning Classification of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OOD_2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ac1342e84ca156574ef657e342945eeee398dc01c0563...</td>\n",
       "      <td>Split used for Producing Plankton Classifiers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ExampleSplitProcessor</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>4495df7f87c537adcdd6312a203a97aac567f5e9fdf971...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_version     OOD         split_strategy filter_strategy  \\\n",
       "0               1                        Unknown  PlanktonFilter   \n",
       "1               2   OOD_2                Unknown  PlanktonFilter   \n",
       "2             NaN     NaN  ExampleSplitProcessor  PlanktonFilter   \n",
       "\n",
       "                                 combined_split_hash  \\\n",
       "0  7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...   \n",
       "1  7ac1342e84ca156574ef657e342945eeee398dc01c0563...   \n",
       "2  4495df7f87c537adcdd6312a203a97aac567f5e9fdf971...   \n",
       "\n",
       "                                         description  \n",
       "0  Split used for Deep Learning Classification of...  \n",
       "1  Split used for Producing Plankton Classifiers ...  \n",
       "2                                               None  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"split_overview_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 11:09:53,883 - lit_ecology_classifier.splitting.split - DEBUG - Class name: Stratified\n",
      "2024-12-16 11:09:53,883 - lit_ecology_classifier.splitting.split - DEBUG - Splitstrategie: Stratified\n",
      "2024-12-16 11:09:53,883 - lit_ecology_classifier.splitting.split - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-16 11:09:53,886 - lit_ecology_classifier.splitting.split - DEBUG - Filterstrategie: PlanktonFilter\n",
      "2024-12-16 11:09:53,886 - lit_ecology_classifier.splitting.split - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-16 11:09:53,887 - lit_ecology_classifier.splitting.split - DEBUG - Class name: Stratified\n",
      "2024-12-16 11:09:53,888 - lit_ecology_classifier.splitting.split - DEBUG - Existing split:Empty DataFrame\n",
      "Columns: [dataset_version, OOD, split_strategy, filter_strategy, combined_split_hash, description]\n",
      "Index: []\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.splitting.split - INFO - No existing split found with the given strategies, creating new split.\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.splitting.split - DEBUG - Importing the modul lit_ecology_classifier.splitting.split_strategies.Stratified\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.splitting.split - DEBUG - Importing the modul lit_ecology_classifier.splitting.filtering.PlanktonFilter\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.splitting.split - DEBUG - Starting filtering of the image overview.\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.helpers.filter - DEBUG - Filtering the dataframe based on the dataset versions: []\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.helpers.filter - DEBUG - No dataset version provided, returning the original dataframe\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.helpers.filter - DEBUG - Filtering the OOD images from the dataframe out.\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.helpers.filter - DEBUG - No OOD defined, not filterig based on the OOD images.\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.splitting.split - DEBUG - Filtering of the image overview completed.\n",
      "2024-12-16 11:09:53,889 - root - INFO - Classes to keep based on defined priority classes, if emtpy no prio are set:[] \n",
      "             Classes to keep based on defined rest classes. If empty, no class are filtered out: []\n",
      "2024-12-16 11:09:53,889 - lit_ecology_classifier.splitting.split - DEBUG - Class map: {'aphanizomenon': 1, 'asplanchna': 2, 'asterionella': 3, 'bosmina': 4, 'brachionus': 5, 'ceratium': 6, 'chaoborus': 7, 'collotheca': 8, 'conochilus': 9, 'copepod_skins': 10, 'cyclops': 11, 'daphnia': 12, 'daphnia_skins': 13, 'diaphanosoma': 14, 'diatom_chain': 15, 'dinobryon': 16, 'dirt': 17, 'eudiaptomus': 18, 'filament': 19, 'fish': 20, 'fragilaria': 21, 'hydra': 22, 'kellicottia': 23, 'keratella_cochlearis': 24, 'keratella_quadrata': 25, 'leptodora': 26, 'maybe_cyano': 27, 'nauplius': 28, 'paradileptus': 29, 'polyarthra': 30, 'rotifers': 31, 'synchaeta': 32, 'trichocerca': 33, 'unknown': 34, 'unknown_plankton': 35, 'uroglena': 36}\n",
      "2024-12-16 11:09:53,896 - lit_ecology_classifier.splitting.split - DEBUG - Filtering of the image overview completed, starting splitting.\n",
      "2024-12-16 11:09:53,897 - lit_ecology_classifier.splitting.split_strategies.stratified - INFO - Performing stratified split. Shape of data:(39162, 14)\n",
      "2024-12-16 11:09:53,903 - lit_ecology_classifier.splitting.split - INFO - Splitted data successfully with Stratified\n",
      "2024-12-16 11:09:53,914 - lit_ecology_classifier.splitting.split - DEBUG - Columns filtered dataframe: Index(['image', 'class', 'sha256', 'date', 'OOD_v2', 'version_1', 'version_2',\n",
      "       'train_v1', 'test_v1', 'val_v1', 'train_v2', 'test_v2', 'val_v2',\n",
      "       'class_map'],\n",
      "      dtype='object')\n",
      "2024-12-16 11:09:53,930 - lit_ecology_classifier.splitting.split - DEBUG - Starting generation of hashes. Split_Df columns: Index(['image', 'class_map', 'split', 'sha256'], dtype='object')\n",
      "2024-12-16 11:09:53,934 - lit_ecology_classifier.splitting.split - DEBUG - Finished generation of hashes.\n",
      "2024-12-16 11:09:53,935 - lit_ecology_classifier.splitting.split - INFO - Split overview updated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class_map</th>\n",
       "      <th>split</th>\n",
       "      <th>sha256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570496498567211-3678476912301-...</td>\n",
       "      <td>27</td>\n",
       "      <td>train</td>\n",
       "      <td>e08bae075ae69dcde0bf83929c8fff5b3bac78e5a91e86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPC-EAWAG-0P5X-1602248934427170-6756627266623-...</td>\n",
       "      <td>34</td>\n",
       "      <td>train</td>\n",
       "      <td>1e1e28cad3f2b9f419ff564df6c3151fc3c4d3c0cd04ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPC-EAWAG-0P5X-1657771518040069-62278380186028...</td>\n",
       "      <td>25</td>\n",
       "      <td>train</td>\n",
       "      <td>778882d5c100a75e52db1b40b34057f7cff661cca5665f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPC-EAWAG-0P5X-1659985235615601-64492066900435...</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "      <td>8262751c828fdb1450702399b2a7266037c8615079a34e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPC-EAWAG-0P5X-1656770957698475-61277833504801...</td>\n",
       "      <td>21</td>\n",
       "      <td>train</td>\n",
       "      <td>9e99e17ed206341d0bdf019667c6b9d1fcf1bb75338b99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39437</th>\n",
       "      <td>SPC-EAWAG-0P5X-1637899349834501-42406507666460...</td>\n",
       "      <td>19</td>\n",
       "      <td>test</td>\n",
       "      <td>c14264dd6af57153fdba959e5e1eb53a0ae0cca4d7d52f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39438</th>\n",
       "      <td>SPC-EAWAG-0P5X-1656907704320527-61414578280829...</td>\n",
       "      <td>28</td>\n",
       "      <td>test</td>\n",
       "      <td>8be1c0bab769b1f241dc461e916df1d963dfd1ec7c567e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39439</th>\n",
       "      <td>SPC-EAWAG-0P5X-1590653329775022-11398720303487...</td>\n",
       "      <td>16</td>\n",
       "      <td>test</td>\n",
       "      <td>a02247a0645fd405168c8b239575d137ba489dd74c451f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39440</th>\n",
       "      <td>SPC-EAWAG-0P5X-1659812915599649-64319749241096...</td>\n",
       "      <td>20</td>\n",
       "      <td>test</td>\n",
       "      <td>2098b9b552be5af76dc1fed870db37e338bfa096ffa48a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39441</th>\n",
       "      <td>SPC-EAWAG-0P5X-1529021641835794-735637579197-0...</td>\n",
       "      <td>16</td>\n",
       "      <td>test</td>\n",
       "      <td>17028e7c117a35584f940b42009d7b778b17ce3bf33ba5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39442 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  class_map  split  \\\n",
       "0      SPC-EAWAG-0P5X-1570496498567211-3678476912301-...         27  train   \n",
       "1      SPC-EAWAG-0P5X-1602248934427170-6756627266623-...         34  train   \n",
       "2      SPC-EAWAG-0P5X-1657771518040069-62278380186028...         25  train   \n",
       "3      SPC-EAWAG-0P5X-1659985235615601-64492066900435...         35  train   \n",
       "4      SPC-EAWAG-0P5X-1656770957698475-61277833504801...         21  train   \n",
       "...                                                  ...        ...    ...   \n",
       "39437  SPC-EAWAG-0P5X-1637899349834501-42406507666460...         19   test   \n",
       "39438  SPC-EAWAG-0P5X-1656907704320527-61414578280829...         28   test   \n",
       "39439  SPC-EAWAG-0P5X-1590653329775022-11398720303487...         16   test   \n",
       "39440  SPC-EAWAG-0P5X-1659812915599649-64319749241096...         20   test   \n",
       "39441  SPC-EAWAG-0P5X-1529021641835794-735637579197-0...         16   test   \n",
       "\n",
       "                                                  sha256  \n",
       "0      e08bae075ae69dcde0bf83929c8fff5b3bac78e5a91e86...  \n",
       "1      1e1e28cad3f2b9f419ff564df6c3151fc3c4d3c0cd04ba...  \n",
       "2      778882d5c100a75e52db1b40b34057f7cff661cca5665f...  \n",
       "3      8262751c828fdb1450702399b2a7266037c8615079a34e...  \n",
       "4      9e99e17ed206341d0bdf019667c6b9d1fcf1bb75338b99...  \n",
       "...                                                  ...  \n",
       "39437  c14264dd6af57153fdba959e5e1eb53a0ae0cca4d7d52f...  \n",
       "39438  8be1c0bab769b1f241dc461e916df1d963dfd1ec7c567e...  \n",
       "39439  a02247a0645fd405168c8b239575d137ba489dd74c451f...  \n",
       "39440  2098b9b552be5af76dc1fed870db37e338bfa096ffa48a...  \n",
       "39441  17028e7c117a35584f940b42009d7b778b17ce3bf33ba5...  \n",
       "\n",
       "[39442 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_processor.search_splits(filter_strategy= \"PlanktonFilter\", split_strategy= \"Stratified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
