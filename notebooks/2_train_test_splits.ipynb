{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Creation of splits\n",
    "This notebook presents how the splits for the models and the dataset version are handlet inside the plankton classifier pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 1 Challenges and requiremnts of the split creation\n",
    "\n",
    "In order to ensure the reproducibility of old splits and to provide enough felxibility to try new split, a own modul was coded that could fulfill following points:\n",
    "\n",
    "- Reproducibility of old splits\n",
    "- Creation of new splits based on past data versions\n",
    "- Consideration of an OOD data set\n",
    "- Simple to implement extensions with own split methods\n",
    "\n",
    "\n",
    "This notebook shows how the split processing is handled, how to use it and how to register a new split version.\n",
    "\n",
    "### 1.1 Requires\n",
    "\n",
    "The notebook requires that all images are saved in the corresponding class folder, irrespective of the dataset version. Additionally, an overview data frame with the splits of the ZooLake version 1 and 2 must be provided. This can be achieved by utilising the notebook `1_data_set_overview.ipynb`, which is included in the notebook directory.\n",
    "\n",
    "### 1.2 Preparations\n",
    "\n",
    "The preparatios includes the navigating to the right dir level, installing the needed package and loading the overview dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 12:27:09,475 - root - DEBUG - Example debug message\n",
      "2024-12-20 12:27:09,476 - root - INFO - Example info message\n",
      "2024-12-20 12:27:09,477 - root - WARNING - Example warning message\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "# Clear existing handlers\n",
    "logger = logging.getLogger()\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Formatter and StreamHandler for the Notebook\n",
    "handler = logging.StreamHandler()\n",
    "\n",
    "# set format with file, line number, function name\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Example log messages\n",
    "logger.debug(\"Example debug message\")\n",
    "logger.info(\"Example info message\")\n",
    "logger.warning(\"Example warning message\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\repos\\plankton_classifier\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: torch in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (0.19.1)\n",
      "Requirement already satisfied: torchaudio in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.4.1)\n",
      "Requirement already satisfied: lightning in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.2.5)\n",
      "Requirement already satisfied: numpy in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.1.1)\n",
      "Requirement already satisfied: scipy in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (1.14.1)\n",
      "Requirement already satisfied: pandas in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (3.9.2)\n",
      "Requirement already satisfied: timm in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (1.0.9)\n",
      "Requirement already satisfied: safetensors in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (0.4.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lit_ecology_classifier==2.0) (1.5.2)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (6.0.2)\n",
      "Requirement already satisfied: fsspec[http]<2025.0,>=2022.5.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (2024.9.0)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (0.11.7)\n",
      "Requirement already satisfied: packaging<25.0,>=20.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (24.1)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (1.4.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (4.12.2)\n",
      "Requirement already satisfied: pytorch-lightning in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning->lit_ecology_classifier==2.0) (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from torch->lit_ecology_classifier==2.0) (3.16.1)\n",
      "Requirement already satisfied: sympy in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from torch->lit_ecology_classifier==2.0) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from torch->lit_ecology_classifier==2.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from torch->lit_ecology_classifier==2.0) (3.1.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from matplotlib->lit_ecology_classifier==2.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from pandas->lit_ecology_classifier==2.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from pandas->lit_ecology_classifier==2.0) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from scikit-learn->lit_ecology_classifier==2.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from scikit-learn->lit_ecology_classifier==2.0) (3.5.0)\n",
      "Requirement already satisfied: huggingface_hub in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from timm->lit_ecology_classifier==2.0) (0.25.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (3.10.6)\n",
      "Requirement already satisfied: setuptools in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from lightning-utilities<2.0,>=0.8.0->lightning->lit_ecology_classifier==2.0) (65.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->lit_ecology_classifier==2.0) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from tqdm<6.0,>=4.57.0->lightning->lit_ecology_classifier==2.0) (0.4.6)\n",
      "Requirement already satisfied: requests in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from huggingface_hub->timm->lit_ecology_classifier==2.0) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from jinja2->torch->lit_ecology_classifier==2.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from sympy->torch->lit_ecology_classifier==2.0) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (2.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning->lit_ecology_classifier==2.0) (1.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->lit_ecology_classifier==2.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->lit_ecology_classifier==2.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->lit_ecology_classifier==2.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\repos\\plankton_classifier\\.venv\\lib\\site-packages (from requests->huggingface_hub->timm->lit_ecology_classifier==2.0) (2024.8.30)\n",
      "Building wheels for collected packages: lit_ecology_classifier\n",
      "  Building wheel for lit_ecology_classifier (pyproject.toml): started\n",
      "  Building wheel for lit_ecology_classifier (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for lit_ecology_classifier: filename=lit_ecology_classifier-2.0-py3-none-any.whl size=101138 sha256=f83ead0997f5292e91ccd02c856f8a42316b9f672de6826ee4d242f17b304c97\n",
      "  Stored in directory: C:\\Users\\ruizjuan\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-7dgvgpnf\\wheels\\ef\\4e\\b8\\2be6c16208ad63911f0ceed2b4bee5a863a52ea77b22187903\n",
      "Successfully built lit_ecology_classifier\n",
      "Installing collected packages: lit_ecology_classifier\n",
      "  Attempting uninstall: lit_ecology_classifier\n",
      "    Found existing installation: lit_ecology_classifier 2.0\n",
      "    Uninstalling lit_ecology_classifier-2.0:\n",
      "      Successfully uninstalled lit_ecology_classifier-2.0\n",
      "Successfully installed lit_ecology_classifier-2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# preparations\n",
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def check_current_work_dir():\n",
    "    if not os.path.isfile(\"setup.py\") or  os.path.basename(os.getcwd()).endswith('notebooks'):\n",
    "        print(\"Changing the current directory to the parent directory containing the setup.py file\")\n",
    "\n",
    "        # move one folder up\n",
    "        os.chdir(\"..\")\n",
    "        print(f\"New current directory: {os.getcwd()}, it will remain this working directory for the rest of the notebook\")\n",
    "\n",
    "    if not os.path.isfile(\"setup.py\"):\n",
    "        raise Exception(\"setup.py not found in the current directory\")\n",
    "\n",
    "check_current_work_dir()\n",
    "\n",
    "check_current_work_dir()\n",
    "# installation of the package \n",
    "# \"%\"  makes the installation from a notebook cell out possible\n",
    "# and \".\" since the setup.py is in the current directory\n",
    "%pip install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>sha256</th>\n",
       "      <th>date</th>\n",
       "      <th>OOD_v2</th>\n",
       "      <th>version_1</th>\n",
       "      <th>version_2</th>\n",
       "      <th>train_v1</th>\n",
       "      <th>test_v1</th>\n",
       "      <th>val_v1</th>\n",
       "      <th>train_v2</th>\n",
       "      <th>test_v2</th>\n",
       "      <th>val_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570543372901157-3725350526242-...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...</td>\n",
       "      <td>2019-10-08 14:02:52+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570543374882008-3725352526408-...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...</td>\n",
       "      <td>2019-10-08 14:02:54+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472012505862-10217420880920...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...</td>\n",
       "      <td>2020-05-14 16:00:12+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472120505648-10217528889899...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...</td>\n",
       "      <td>2020-05-14 16:02:00+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472215513831-10217623897796...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>9cfb8f3f9d36cb50c32bedc72724092a7a01576ccb8529...</td>\n",
       "      <td>2020-05-14 16:03:35+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image          class  \\\n",
       "0  SPC-EAWAG-0P5X-1570543372901157-3725350526242-...  aphanizomenon   \n",
       "1  SPC-EAWAG-0P5X-1570543374882008-3725352526408-...  aphanizomenon   \n",
       "2  SPC-EAWAG-0P5X-1589472012505862-10217420880920...  aphanizomenon   \n",
       "3  SPC-EAWAG-0P5X-1589472120505648-10217528889899...  aphanizomenon   \n",
       "4  SPC-EAWAG-0P5X-1589472215513831-10217623897796...  aphanizomenon   \n",
       "\n",
       "                                              sha256  \\\n",
       "0  6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...   \n",
       "1  09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...   \n",
       "2  1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...   \n",
       "3  f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...   \n",
       "4  9cfb8f3f9d36cb50c32bedc72724092a7a01576ccb8529...   \n",
       "\n",
       "                        date  OOD_v2  version_1  version_2  train_v1  test_v1  \\\n",
       "0  2019-10-08 14:02:52+00:00   False       True       True      True    False   \n",
       "1  2019-10-08 14:02:54+00:00   False       True       True      True    False   \n",
       "2  2020-05-14 16:00:12+00:00   False       True       True      True    False   \n",
       "3  2020-05-14 16:02:00+00:00   False       True       True      True    False   \n",
       "4  2020-05-14 16:03:35+00:00   False       True       True     False    False   \n",
       "\n",
       "   val_v1  train_v2  test_v2  val_v2  \n",
       "0   False      True    False   False  \n",
       "1   False     False     True   False  \n",
       "2   False      True    False   False  \n",
       "3   False      True    False   False  \n",
       "4    True      True    False   False  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the overview data\n",
    "path = os.path.join(\"data\", \"interim\",  \"overview.csv\")\n",
    "df = pd.read_csv( filepath_or_buffer= path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>sha256</th>\n",
       "      <th>split</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29640</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624734366033156-29241721188723...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>f918287e56745c04bda26e4e41c7410829460f1e00c9b8...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29641</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624662155318571-29169511575069...</td>\n",
       "      <td>asplanchna</td>\n",
       "      <td>a09365d3b45b8d69976b0796f885d51c8763b7e035def9...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29642</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624662157341137-29169513575235...</td>\n",
       "      <td>asplanchna</td>\n",
       "      <td>a4ca7d1c4daac22313245706347e3544fa90722273472c...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29643</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624662354355777-29169710591612...</td>\n",
       "      <td>asplanchna</td>\n",
       "      <td>55df99360fdc74e9485846e4d836232df919e832e23a1e...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29644</th>\n",
       "      <td>SPC-EAWAG-0P5X-1624662437359090-29169793598512...</td>\n",
       "      <td>asplanchna</td>\n",
       "      <td>1610bc0981eb9b8543fa0a4e8b6afaa1a22788b6fdbcbc...</td>\n",
       "      <td>OOD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image          class  \\\n",
       "29640  SPC-EAWAG-0P5X-1624734366033156-29241721188723...  aphanizomenon   \n",
       "29641  SPC-EAWAG-0P5X-1624662155318571-29169511575069...     asplanchna   \n",
       "29642  SPC-EAWAG-0P5X-1624662157341137-29169513575235...     asplanchna   \n",
       "29643  SPC-EAWAG-0P5X-1624662354355777-29169710591612...     asplanchna   \n",
       "29644  SPC-EAWAG-0P5X-1624662437359090-29169793598512...     asplanchna   \n",
       "\n",
       "                                                  sha256 split version  \n",
       "29640  f918287e56745c04bda26e4e41c7410829460f1e00c9b8...   OOD       2  \n",
       "29641  a09365d3b45b8d69976b0796f885d51c8763b7e035def9...   OOD       2  \n",
       "29642  a4ca7d1c4daac22313245706347e3544fa90722273472c...   OOD       2  \n",
       "29643  55df99360fdc74e9485846e4d836232df919e832e23a1e...   OOD       2  \n",
       "29644  1610bc0981eb9b8543fa0a4e8b6afaa1a22788b6fdbcbc...   OOD       2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation to a tidy format\n",
    "df = df.filter(regex=\"train|test|val|image|class|sha256|OOD\")\n",
    "\n",
    "# Melt test, train, and val columns into one column per row and version\n",
    "df_melted = df.filter(regex=\"v1|v2|image|class|sha256\").melt(\n",
    "    id_vars=['image', 'class', 'sha256'],\n",
    "    var_name='split'\n",
    ")\n",
    "\n",
    "# Extract 'version' and 'split' from the 'split' column using vectorized string methods\n",
    "df_melted[\"version\"] = df_melted[\"split\"].str.split('_').str[1]\n",
    "df_melted[\"split\"] = df_melted[\"split\"].str.split('_').str[0]\n",
    "\n",
    "# Keep only rows where 'value' is 1\n",
    "df_melted = df_melted[df_melted['value'] == 1]\n",
    "\n",
    "# Replace version labels for consistency\n",
    "df_melted[\"version\"] = df_melted[\"version\"].replace({\"v1\": \"1\", \"v2\": \"2\"})\n",
    "\n",
    "# Drop the 'value' column as it's no longer needed\n",
    "df_melted = df_melted.drop(columns=\"value\")\n",
    "\n",
    "# Display the first few rows of the transformed dataframe\n",
    "df_melted.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2 Split Overview\n",
    "\n",
    "The split overview was created with the ambition to keep informations and track of the used split. It includes following columns:\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\n",
    "\\begin{array}{c}\n",
    "\\textbf{Description of the split overview dataframe}\\\\\n",
    "\\newline\n",
    "\\begin{array}{|l|l|}\n",
    "\\hline\n",
    "\\textbf{Column name} & \\textbf{Description} \\\\\n",
    "\\hline\n",
    "\\text{dataset version} & \\text{Version of the Dataset used for the split} \\\\\n",
    "\\text{OOD} & \\text{OOD version included in the split} \\\\\n",
    "\\text{split strategy} & \\text{Used split strategy} \\\\\n",
    "\\text{combined split hash} & \\text{Hash value to identfiy and check the split} \\\\\n",
    "\\text{Description} & \\text{Place to add a short description of the split} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\\end{array}\n",
    "\n",
    "$$\n",
    "\n",
    "\\\n",
    "The current status of the split overview can be found in the folder \"interim\\UsedSplit\\\". Nevertheless, the intention is to store the overview split in a database in the near future.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_version</th>\n",
       "      <th>OOD</th>\n",
       "      <th>split_strategy</th>\n",
       "      <th>filter_strategy</th>\n",
       "      <th>combined_split_hash</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...</td>\n",
       "      <td>Split used for Deep Learning Classification of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OOD_2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ac1342e84ca156574ef657e342945eeee398dc01c0563...</td>\n",
       "      <td>Split used for Producing Plankton Classifiers ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_version     OOD split_strategy filter_strategy  \\\n",
       "0               1                Unknown  PlanktonFilter   \n",
       "1               2   OOD_2        Unknown  PlanktonFilter   \n",
       "\n",
       "                                 combined_split_hash  \\\n",
       "0  7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...   \n",
       "1  7ac1342e84ca156574ef657e342945eeee398dc01c0563...   \n",
       "\n",
       "                                         description  \n",
       "0  Split used for Deep Learning Classification of...  \n",
       "1  Split used for Producing Plankton Classifiers ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading of the split overview \n",
    "path = os.path.join(\"data\", \"interim\", \"UsedSplits\", \"split_overview.csv\")\n",
    "\n",
    "types = {\n",
    "    \"dataset_version\": \"str\",\n",
    "    \"OOD\": \"str\",\n",
    "    \"split_strategy\": \"str\",\n",
    "    \"combined_split_hash\": \"str\",\n",
    "    \"fescription\": \"str\"\n",
    "}\n",
    "\n",
    "split_overview = pd.read_csv(filepath_or_buffer= path, index_col=False, dtype=types)\n",
    "split_overview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Split hashes and comnined split hash\n",
    "\n",
    "In order to not only store information but also to verify whether the reconstructed splits align with the original ones,  the property of hashing was again utilised based on the  images hashesh.\n",
    "\n",
    "### 3.1 Split hashes\n",
    "\n",
    "The split hashes are calculated based on a sorted join of each hash within each unique value of the column \"split\".  This is shown for the first Zoolake version below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': '3dc0e5aadb042c37d8e52908b23c9b0af83e2497109e7e1c5a25d2b65c5e14be',\n",
       " 'train': 'bc9bb5d05fbdd28547737c9953d10fa3f584e9a832dc7e2c75d1b6751f5a2024',\n",
       " 'val': '1d24484776f9579e8bdd468c884dd4df15eb4429ea89d136fed636245d8c49e9'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of the split hashes \n",
    "\n",
    "from lit_ecology_classifier.helpers.hashing import HashGenerator\n",
    "\n",
    "# filter to calculate the hashes for the first version\n",
    "df_v1 = df_melted[df_melted[\"version\"] == \"1\"]\n",
    "\n",
    "# generate the hashes\n",
    "hashes_v1 = HashGenerator().generate_hash_dict_from_split(df_v1, col_to_hash =\"sha256\", group_by_col= \"split\")\n",
    "\n",
    "hashes_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated by the output, the values of the dictionary represent the calculated hash value for each split. This makes it possible to find out if each reproduced split  correspond to the original one.\n",
    "\n",
    "### 3.1 Combined split hashes\n",
    "A value per split presents the disadvantage of complicating a direct comparison of whether the entire split is identical. For this reason, the individual hash values are sorted and hashed again. This leads to the loss of knwoing wich hash differs now. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214c00e80c52845c5eaed'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_hash = HashGenerator().sha256_from_list(hashes_v1.values())    \n",
    "combined_hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilisation of the images and split hashes permits the theoretical identification down to the pixel value whether the splits are identical or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 SplitProcessor\n",
    "\n",
    "In order to fulfil the necessary requirements to create and recreate old splits, the class `SplitProcessor` was implemented. The Split Processor provides the main functionalities to manage all aspects of the data splitting process, including the checking of existing splits, the creation of new splits and the execution of the image copying. \n",
    "\n",
    "The implementation of the split processor is object-oriented, employing polymorphism for the split strategy and inheritance of the `base_image_mover.py` functionalities for the copying of the images. \n",
    "\n",
    "At the momement, the created splits and overview are stored inside the file folder `interim\\UsedSplit\\`  However, it is intended that this will be replaced in the near future with a database.\n",
    "\n",
    "### 4.1 Attributes\n",
    "\n",
    "xyz\n",
    "\n",
    "\n",
    "### 4.2 How to use\n",
    "\n",
    "\n",
    "#### 4.2.1 Recreation of splits \n",
    "\n",
    "To recreate a used split the split strategy, dataset version and OOD Version need to be defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 12:27:19,862 - matplotlib - DEBUG - matplotlib data path: c:\\Repos\\plankton_classifier\\.venv\\Lib\\site-packages\\matplotlib\\mpl-data\n",
      "2024-12-20 12:27:19,866 - matplotlib - DEBUG - CONFIGDIR=C:\\Users\\ruizjuan\\.matplotlib\n",
      "2024-12-20 12:27:19,898 - matplotlib - DEBUG - interactive is False\n",
      "2024-12-20 12:27:19,899 - matplotlib - DEBUG - platform is win32\n",
      "2024-12-20 12:27:19,963 - matplotlib - DEBUG - CACHEDIR=C:\\Users\\ruizjuan\\.matplotlib\n",
      "2024-12-20 12:27:19,965 - matplotlib.font_manager - DEBUG - Using fontManager instance from C:\\Users\\ruizjuan\\.matplotlib\\fontlist-v390.json\n",
      "2024-12-20 12:27:22,284 - lit_ecology_classifier.splitting.split_processor - DEBUG - Image overview column types: image        object\n",
      "class        object\n",
      "sha256       object\n",
      "date         object\n",
      "OOD_v2         bool\n",
      "version_1      bool\n",
      "version_2      bool\n",
      "train_v1       bool\n",
      "test_v1        bool\n",
      "val_v1         bool\n",
      "train_v2       bool\n",
      "test_v2        bool\n",
      "val_v2         bool\n",
      "dtype: object\n",
      "2024-12-20 12:27:22,284 - lit_ecology_classifier.splitting.split_processor - INFO - Split overview loaded.\n",
      "2024-12-20 12:27:22,284 - lit_ecology_classifier.splitting.split_processor - DEBUG - Updated split args: {}\n",
      "2024-12-20 12:27:22,284 - lit_ecology_classifier.splitting.split_processor - DEBUG - Updated filter args: {}\n",
      "2024-12-20 12:27:22,284 - lit_ecology_classifier.splitting.split_processor - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-20 12:27:22,284 - lit_ecology_classifier.splitting.split_processor - DEBUG - Class name: Unknown\n",
      "2024-12-20 12:27:22,284 - lit_ecology_classifier.splitting.split_processor - INFO - Existing split found, reloading split.\n",
      "2024-12-20 12:27:22,284 - lit_ecology_classifier.splitting.split_processor - INFO - Reloading split based on hash value: 7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214c00e80c52845c5ea\n",
      "2024-12-20 12:27:22,284 - lit_ecology_classifier.splitting.split_processor - INFO - Split file path: data\\interim\\UsedSplits\\7ae8bedcd1f7b93380ada9d9.csv\n"
     ]
    }
   ],
   "source": [
    "# recreation of a split\n",
    "from lit_ecology_classifier.splitting.split_processor import SplitProcessor\n",
    "\n",
    "split_processor = SplitProcessor(\n",
    "                                split_overview = split_overview,\n",
    "                                split_folder = r\"data\\interim\\UsedSplits\",\n",
    "                                image_overview= \"data\\interim\\overview.csv\",\n",
    "                                split_strategy= 'Unknown',\n",
    "                                filter_strategy= 'PlanktonFilter'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "      <th>sha256</th>\n",
       "      <th>split</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570543372901157-3725350526242-...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPC-EAWAG-0P5X-1570543374882008-3725352526408-...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472012505862-10217420880920...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472120505648-10217528889899...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589472588541825-10217996928805...</td>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>5ca3294d8df48501fd83731564c93442fedd1002c1b6f4...</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18079</th>\n",
       "      <td>SPC-EAWAG-0P5X-1563195834608473-10101205289100...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>225a67488e4bab2ece16cf9fc2c013524608601c7b2350...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18080</th>\n",
       "      <td>SPC-EAWAG-0P5X-1563196067636305-10101438308470...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>64882fcbfbc4aff5835c4cd21e16a0201c1a12a51c4d98...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18081</th>\n",
       "      <td>SPC-EAWAG-0P5X-1575370922015129-8552825698030-...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>240ef901638276c790bb83c791b48eb04ecd09b53bcc43...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18082</th>\n",
       "      <td>SPC-EAWAG-0P5X-1589537321913540-10282729292872...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>f5edd8827d77807a30626961e984e3536f66fe30d2b0c7...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18083</th>\n",
       "      <td>SPC-EAWAG-0P5X-1591675305662922-12420681042323...</td>\n",
       "      <td>keratella_cochlearis</td>\n",
       "      <td>459b730831e5bbe33f689d783b79b8a2343a156934db0a...</td>\n",
       "      <td>val</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18084 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  \\\n",
       "0      SPC-EAWAG-0P5X-1570543372901157-3725350526242-...   \n",
       "1      SPC-EAWAG-0P5X-1570543374882008-3725352526408-...   \n",
       "2      SPC-EAWAG-0P5X-1589472012505862-10217420880920...   \n",
       "3      SPC-EAWAG-0P5X-1589472120505648-10217528889899...   \n",
       "4      SPC-EAWAG-0P5X-1589472588541825-10217996928805...   \n",
       "...                                                  ...   \n",
       "18079  SPC-EAWAG-0P5X-1563195834608473-10101205289100...   \n",
       "18080  SPC-EAWAG-0P5X-1563196067636305-10101438308470...   \n",
       "18081  SPC-EAWAG-0P5X-1575370922015129-8552825698030-...   \n",
       "18082  SPC-EAWAG-0P5X-1589537321913540-10282729292872...   \n",
       "18083  SPC-EAWAG-0P5X-1591675305662922-12420681042323...   \n",
       "\n",
       "                      class  \\\n",
       "0             aphanizomenon   \n",
       "1             aphanizomenon   \n",
       "2             aphanizomenon   \n",
       "3             aphanizomenon   \n",
       "4             aphanizomenon   \n",
       "...                     ...   \n",
       "18079  keratella_cochlearis   \n",
       "18080  keratella_cochlearis   \n",
       "18081  keratella_cochlearis   \n",
       "18082  keratella_cochlearis   \n",
       "18083  keratella_cochlearis   \n",
       "\n",
       "                                                  sha256  split  version  \n",
       "0      6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...  train        1  \n",
       "1      09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...  train        1  \n",
       "2      1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...  train        1  \n",
       "3      f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...  train        1  \n",
       "4      5ca3294d8df48501fd83731564c93442fedd1002c1b6f4...  train        1  \n",
       "...                                                  ...    ...      ...  \n",
       "18079  225a67488e4bab2ece16cf9fc2c013524608601c7b2350...    val        1  \n",
       "18080  64882fcbfbc4aff5835c4cd21e16a0201c1a12a51c4d98...    val        1  \n",
       "18081  240ef901638276c790bb83c791b48eb04ecd09b53bcc43...    val        1  \n",
       "18082  f5edd8827d77807a30626961e984e3536f66fe30d2b0c7...    val        1  \n",
       "18083  459b730831e5bbe33f689d783b79b8a2343a156934db0a...    val        1  \n",
       "\n",
       "[18084 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"split_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Use of build in split strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 12:27:22,406 - lit_ecology_classifier.splitting.split_processor - DEBUG - Image overview column types: image        object\n",
      "class        object\n",
      "sha256       object\n",
      "date         object\n",
      "OOD_v2         bool\n",
      "version_1      bool\n",
      "version_2      bool\n",
      "train_v1       bool\n",
      "test_v1        bool\n",
      "val_v1         bool\n",
      "train_v2       bool\n",
      "test_v2        bool\n",
      "val_v2         bool\n",
      "dtype: object\n",
      "2024-12-20 12:27:22,407 - lit_ecology_classifier.splitting.split_processor - INFO - Split overview loaded.\n",
      "2024-12-20 12:27:22,407 - lit_ecology_classifier.splitting.split_processor - DEBUG - Updated split args: {}\n",
      "2024-12-20 12:27:22,407 - lit_ecology_classifier.splitting.split_processor - DEBUG - Updated filter args: {}\n",
      "2024-12-20 12:27:22,408 - lit_ecology_classifier.splitting.split_processor - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-20 12:27:22,408 - lit_ecology_classifier.splitting.split_processor - DEBUG - Class name: Stratified\n",
      "2024-12-20 12:27:22,409 - lit_ecology_classifier.splitting.split_processor - INFO - No existing split found, creating a new split.\n",
      "2024-12-20 12:27:22,410 - lit_ecology_classifier.splitting.split_processor - INFO - Creating a new split based on the given split and filter strategy.:<class 'pandas.core.frame.DataFrame'>\n",
      "2024-12-20 12:27:22,410 - lit_ecology_classifier.helpers.helpers - DEBUG - Importing the modul lit_ecology_classifier.splitting.filtering.PlanktonFilter\n",
      "2024-12-20 12:27:22,411 - lit_ecology_classifier.helpers.filter - DEBUG - Filtering the dataframe based on the dataset versions: []\n",
      "2024-12-20 12:27:22,412 - lit_ecology_classifier.helpers.filter - DEBUG - No dataset version provided, returning the original dataframe\n",
      "2024-12-20 12:27:22,412 - lit_ecology_classifier.helpers.filter - DEBUG - No OOD defined, not filterig based on the OOD images.\n",
      "2024-12-20 12:27:22,413 - lit_ecology_classifier.splitting.split_processor - INFO - No class map provided, generating class map.\n",
      "2024-12-20 12:27:22,413 - lit_ecology_classifier.helpers.helpers - DEBUG - Creating the class mapping based on the unique class labels.\n",
      "2024-12-20 12:27:22,415 - lit_ecology_classifier.helpers.helpers - DEBUG - Unique class labels found: ['aphanizomenon' 'asplanchna' 'asterionella' 'bosmina' 'brachionus'\n",
      " 'ceratium' 'chaoborus' 'conochilus' 'copepod_skins' 'cyclops' 'daphnia'\n",
      " 'daphnia_skins' 'diaphanosoma' 'diatom_chain' 'dinobryon' 'dirt'\n",
      " 'eudiaptomus' 'filament' 'fish' 'fragilaria' 'hydra' 'kellicottia'\n",
      " 'keratella_cochlearis' 'keratella_quadrata' 'leptodora' 'maybe_cyano'\n",
      " 'nauplius' 'paradileptus' 'polyarthra' 'rotifers' 'synchaeta'\n",
      " 'trichocerca' 'unknown' 'unknown_plankton' 'uroglena' 'collotheca']\n",
      "2024-12-20 12:27:22,415 - lit_ecology_classifier.splitting.split_processor - INFO - Class map generated: {'aphanizomenon': 1, 'asplanchna': 2, 'asterionella': 3, 'bosmina': 4, 'brachionus': 5, 'ceratium': 6, 'chaoborus': 7, 'collotheca': 8, 'conochilus': 9, 'copepod_skins': 10, 'cyclops': 11, 'daphnia': 12, 'daphnia_skins': 13, 'diaphanosoma': 14, 'diatom_chain': 15, 'dinobryon': 16, 'dirt': 17, 'eudiaptomus': 18, 'filament': 19, 'fish': 20, 'fragilaria': 21, 'hydra': 22, 'kellicottia': 23, 'keratella_cochlearis': 24, 'keratella_quadrata': 25, 'leptodora': 26, 'maybe_cyano': 27, 'nauplius': 28, 'paradileptus': 29, 'polyarthra': 30, 'rotifers': 31, 'synchaeta': 32, 'trichocerca': 33, 'unknown': 34, 'unknown_plankton': 35, 'uroglena': 36}\n",
      "2024-12-20 12:27:22,416 - root - INFO - Classes to keep based on defined priority classes, if emtpy no prio are set:[] \n",
      "             Classes to keep based on defined rest classes. If empty, no class are filtered out: []\n",
      "2024-12-20 12:27:22,416 - lit_ecology_classifier.splitting.split_processor - INFO - Class map generated: {'aphanizomenon': 1, 'asplanchna': 2, 'asterionella': 3, 'bosmina': 4, 'brachionus': 5, 'ceratium': 6, 'chaoborus': 7, 'collotheca': 8, 'conochilus': 9, 'copepod_skins': 10, 'cyclops': 11, 'daphnia': 12, 'daphnia_skins': 13, 'diaphanosoma': 14, 'diatom_chain': 15, 'dinobryon': 16, 'dirt': 17, 'eudiaptomus': 18, 'filament': 19, 'fish': 20, 'fragilaria': 21, 'hydra': 22, 'kellicottia': 23, 'keratella_cochlearis': 24, 'keratella_quadrata': 25, 'leptodora': 26, 'maybe_cyano': 27, 'nauplius': 28, 'paradileptus': 29, 'polyarthra': 30, 'rotifers': 31, 'synchaeta': 32, 'trichocerca': 33, 'unknown': 34, 'unknown_plankton': 35, 'uroglena': 36}\n",
      "2024-12-20 12:27:22,427 - lit_ecology_classifier.helpers.helpers - DEBUG - Importing the modul lit_ecology_classifier.splitting.split_strategies.Stratified\n",
      "2024-12-20 12:27:22,451 - lit_ecology_classifier.splitting.split_strategies.stratified - INFO - Performing stratified split. Shape of data:(39162, 14)\n"
     ]
    }
   ],
   "source": [
    "split_processor = SplitProcessor(\n",
    "                                split_strategy= 'Stratified',\n",
    "                                filter_strategy= 'PlanktonFilter',\n",
    "                                split_overview = split_overview, \n",
    "                                image_overview= r\"data\\interim\\overview.csv\",\n",
    "                                filter_args= {\"dataset_version\":\"1\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_version</th>\n",
       "      <th>OOD</th>\n",
       "      <th>split_strategy</th>\n",
       "      <th>filter_strategy</th>\n",
       "      <th>combined_split_hash</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...</td>\n",
       "      <td>Split used for Deep Learning Classification of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OOD_2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ac1342e84ca156574ef657e342945eeee398dc01c0563...</td>\n",
       "      <td>Split used for Producing Plankton Classifiers ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_version     OOD split_strategy filter_strategy  \\\n",
       "0               1                Unknown  PlanktonFilter   \n",
       "1               2   OOD_2        Unknown  PlanktonFilter   \n",
       "\n",
       "                                 combined_split_hash  \\\n",
       "0  7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...   \n",
       "1  7ac1342e84ca156574ef657e342945eeee398dc01c0563...   \n",
       "\n",
       "                                         description  \n",
       "0  Split used for Deep Learning Classification of...  \n",
       "1  Split used for Producing Plankton Classifiers ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"split_overview_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "      <th>sha256</th>\n",
       "      <th>date</th>\n",
       "      <th>OOD_v2</th>\n",
       "      <th>version_1</th>\n",
       "      <th>version_2</th>\n",
       "      <th>train_v1</th>\n",
       "      <th>test_v1</th>\n",
       "      <th>val_v1</th>\n",
       "      <th>train_v2</th>\n",
       "      <th>test_v2</th>\n",
       "      <th>val_v2</th>\n",
       "      <th>class_map_x</th>\n",
       "      <th>class_map_y</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1570543372901157-3725350526242-...</td>\n",
       "      <td>6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...</td>\n",
       "      <td>2019-10-08 14:02:52+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1570543374882008-3725352526408-...</td>\n",
       "      <td>09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...</td>\n",
       "      <td>2019-10-08 14:02:54+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1589472012505862-10217420880920...</td>\n",
       "      <td>1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...</td>\n",
       "      <td>2020-05-14 16:00:12+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1589472120505648-10217528889899...</td>\n",
       "      <td>f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...</td>\n",
       "      <td>2020-05-14 16:02:00+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1589472215513831-10217623897796...</td>\n",
       "      <td>9cfb8f3f9d36cb50c32bedc72724092a7a01576ccb8529...</td>\n",
       "      <td>2020-05-14 16:03:35+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39437</th>\n",
       "      <td>unknown_plankton</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628924603886864-33431897306214...</td>\n",
       "      <td>f37b8728341c8523cae1e78a3014c1b4aa0f4741553c67...</td>\n",
       "      <td>2021-08-14 07:03:23+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39438</th>\n",
       "      <td>unknown_plankton</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628946228440913-33453521474102...</td>\n",
       "      <td>e0753b2f321e28fb34885cb5b08e1107e943345ca014ce...</td>\n",
       "      <td>2021-08-14 13:03:48+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39439</th>\n",
       "      <td>unknown_plankton</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628953524258605-33460817200807...</td>\n",
       "      <td>b6060aca8743971e66fbcd835dbfaa3ccc7676ba02543d...</td>\n",
       "      <td>2021-08-14 15:05:24+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39440</th>\n",
       "      <td>unknown_plankton</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628960940234482-33468233086890...</td>\n",
       "      <td>f422c45d51225872818e04396413ce42ea2b391da13dd9...</td>\n",
       "      <td>2021-08-14 17:09:00+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39441</th>\n",
       "      <td>uroglena</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628899698205785-33406991970972...</td>\n",
       "      <td>5ec2e22016e6e7c812b61beb997b81af92cf351d2fc180...</td>\n",
       "      <td>2021-08-14 00:08:18+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39442 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  class                                              image  \\\n",
       "0         aphanizomenon  SPC-EAWAG-0P5X-1570543372901157-3725350526242-...   \n",
       "1         aphanizomenon  SPC-EAWAG-0P5X-1570543374882008-3725352526408-...   \n",
       "2         aphanizomenon  SPC-EAWAG-0P5X-1589472012505862-10217420880920...   \n",
       "3         aphanizomenon  SPC-EAWAG-0P5X-1589472120505648-10217528889899...   \n",
       "4         aphanizomenon  SPC-EAWAG-0P5X-1589472215513831-10217623897796...   \n",
       "...                 ...                                                ...   \n",
       "39437  unknown_plankton  SPC-EAWAG-0P5X-1628924603886864-33431897306214...   \n",
       "39438  unknown_plankton  SPC-EAWAG-0P5X-1628946228440913-33453521474102...   \n",
       "39439  unknown_plankton  SPC-EAWAG-0P5X-1628953524258605-33460817200807...   \n",
       "39440  unknown_plankton  SPC-EAWAG-0P5X-1628960940234482-33468233086890...   \n",
       "39441          uroglena  SPC-EAWAG-0P5X-1628899698205785-33406991970972...   \n",
       "\n",
       "                                                  sha256  \\\n",
       "0      6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...   \n",
       "1      09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...   \n",
       "2      1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...   \n",
       "3      f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...   \n",
       "4      9cfb8f3f9d36cb50c32bedc72724092a7a01576ccb8529...   \n",
       "...                                                  ...   \n",
       "39437  f37b8728341c8523cae1e78a3014c1b4aa0f4741553c67...   \n",
       "39438  e0753b2f321e28fb34885cb5b08e1107e943345ca014ce...   \n",
       "39439  b6060aca8743971e66fbcd835dbfaa3ccc7676ba02543d...   \n",
       "39440  f422c45d51225872818e04396413ce42ea2b391da13dd9...   \n",
       "39441  5ec2e22016e6e7c812b61beb997b81af92cf351d2fc180...   \n",
       "\n",
       "                            date  OOD_v2  version_1  version_2  train_v1  \\\n",
       "0      2019-10-08 14:02:52+00:00   False       True       True      True   \n",
       "1      2019-10-08 14:02:54+00:00   False       True       True      True   \n",
       "2      2020-05-14 16:00:12+00:00   False       True       True      True   \n",
       "3      2020-05-14 16:02:00+00:00   False       True       True      True   \n",
       "4      2020-05-14 16:03:35+00:00   False       True       True     False   \n",
       "...                          ...     ...        ...        ...       ...   \n",
       "39437  2021-08-14 07:03:23+00:00    True      False       True     False   \n",
       "39438  2021-08-14 13:03:48+00:00    True      False       True     False   \n",
       "39439  2021-08-14 15:05:24+00:00    True      False       True     False   \n",
       "39440  2021-08-14 17:09:00+00:00    True      False       True     False   \n",
       "39441  2021-08-14 00:08:18+00:00    True      False       True     False   \n",
       "\n",
       "       test_v1  val_v1  train_v2  test_v2  val_v2  class_map_x  class_map_y  \\\n",
       "0        False   False      True    False   False            1            1   \n",
       "1        False   False     False     True   False            1            1   \n",
       "2        False   False      True    False   False            1            1   \n",
       "3        False   False      True    False   False            1            1   \n",
       "4        False    True      True    False   False            1            1   \n",
       "...        ...     ...       ...      ...     ...          ...          ...   \n",
       "39437    False   False     False    False   False           35           35   \n",
       "39438    False   False     False    False   False           35           35   \n",
       "39439    False   False     False    False   False           35           35   \n",
       "39440    False   False     False    False   False           35           35   \n",
       "39441    False   False     False    False   False           36           36   \n",
       "\n",
       "       split  \n",
       "0      train  \n",
       "1       test  \n",
       "2      train  \n",
       "3      train  \n",
       "4       test  \n",
       "...      ...  \n",
       "39437  train  \n",
       "39438  train  \n",
       "39439  train  \n",
       "39440  train  \n",
       "39441  train  \n",
       "\n",
       "[39442 rows x 16 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"split_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aphanizomenon': 1,\n",
       " 'asplanchna': 2,\n",
       " 'asterionella': 3,\n",
       " 'bosmina': 4,\n",
       " 'brachionus': 5,\n",
       " 'ceratium': 6,\n",
       " 'chaoborus': 7,\n",
       " 'collotheca': 8,\n",
       " 'conochilus': 9,\n",
       " 'copepod_skins': 10,\n",
       " 'cyclops': 11,\n",
       " 'daphnia': 12,\n",
       " 'daphnia_skins': 13,\n",
       " 'diaphanosoma': 14,\n",
       " 'diatom_chain': 15,\n",
       " 'dinobryon': 16,\n",
       " 'dirt': 17,\n",
       " 'eudiaptomus': 18,\n",
       " 'filament': 19,\n",
       " 'fish': 20,\n",
       " 'fragilaria': 21,\n",
       " 'hydra': 22,\n",
       " 'kellicottia': 23,\n",
       " 'keratella_cochlearis': 24,\n",
       " 'keratella_quadrata': 25,\n",
       " 'leptodora': 26,\n",
       " 'maybe_cyano': 27,\n",
       " 'nauplius': 28,\n",
       " 'paradileptus': 29,\n",
       " 'polyarthra': 30,\n",
       " 'rotifers': 31,\n",
       " 'synchaeta': 32,\n",
       " 'trichocerca': 33,\n",
       " 'unknown': 34,\n",
       " 'unknown_plankton': 35,\n",
       " 'uroglena': 36}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"class_map\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useage with own splot strategie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lit_ecology_classifier.splitting.split_strategies.base_split_strategy import BaseSplitStrategy\n",
    "\n",
    "class ExampleSplitProcessor(BaseSplitStrategy):\n",
    "\n",
    "    def perform_split(self, df, y_col = \"class_map\"):\n",
    "        X = df[\"image\"]\n",
    "        y = df[y_col]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        return {\n",
    "            \"train\": [X_train,y_train],\n",
    "            \"test\": [X_test, y_test]    \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.splitting.split_processor - DEBUG - Image overview column types: image        object\n",
      "class        object\n",
      "sha256       object\n",
      "date         object\n",
      "OOD_v2         bool\n",
      "version_1      bool\n",
      "version_2      bool\n",
      "train_v1       bool\n",
      "test_v1        bool\n",
      "val_v1         bool\n",
      "train_v2       bool\n",
      "test_v2        bool\n",
      "val_v2         bool\n",
      "dtype: object\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.splitting.split_processor - INFO - Split overview loaded.\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.splitting.split_processor - DEBUG - Updated split args: {}\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.splitting.split_processor - DEBUG - Updated filter args: {}\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.splitting.split_processor - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.splitting.split_processor - DEBUG - Class name: ExampleSplitProcessor\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.splitting.split_processor - INFO - No existing split found, creating a new split.\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.splitting.split_processor - INFO - Creating a new split based on the given split and filter strategy.:<class 'pandas.core.frame.DataFrame'>\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.helpers.helpers - DEBUG - Importing the modul lit_ecology_classifier.splitting.filtering.PlanktonFilter\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.helpers.filter - DEBUG - Filtering the dataframe based on the dataset versions: []\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.helpers.filter - DEBUG - No dataset version provided, returning the original dataframe\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.helpers.filter - DEBUG - No OOD defined, not filterig based on the OOD images.\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.splitting.split_processor - INFO - No class map provided, generating class map.\n",
      "2024-12-20 12:27:22,601 - lit_ecology_classifier.helpers.helpers - DEBUG - Creating the class mapping based on the unique class labels.\n",
      "2024-12-20 12:27:22,611 - lit_ecology_classifier.helpers.helpers - DEBUG - Unique class labels found: ['aphanizomenon' 'asplanchna' 'asterionella' 'bosmina' 'brachionus'\n",
      " 'ceratium' 'chaoborus' 'conochilus' 'copepod_skins' 'cyclops' 'daphnia'\n",
      " 'daphnia_skins' 'diaphanosoma' 'diatom_chain' 'dinobryon' 'dirt'\n",
      " 'eudiaptomus' 'filament' 'fish' 'fragilaria' 'hydra' 'kellicottia'\n",
      " 'keratella_cochlearis' 'keratella_quadrata' 'leptodora' 'maybe_cyano'\n",
      " 'nauplius' 'paradileptus' 'polyarthra' 'rotifers' 'synchaeta'\n",
      " 'trichocerca' 'unknown' 'unknown_plankton' 'uroglena' 'collotheca']\n",
      "2024-12-20 12:27:22,611 - lit_ecology_classifier.splitting.split_processor - INFO - Class map generated: {'aphanizomenon': 1, 'asplanchna': 2, 'asterionella': 3, 'bosmina': 4, 'brachionus': 5, 'ceratium': 6, 'chaoborus': 7, 'collotheca': 8, 'conochilus': 9, 'copepod_skins': 10, 'cyclops': 11, 'daphnia': 12, 'daphnia_skins': 13, 'diaphanosoma': 14, 'diatom_chain': 15, 'dinobryon': 16, 'dirt': 17, 'eudiaptomus': 18, 'filament': 19, 'fish': 20, 'fragilaria': 21, 'hydra': 22, 'kellicottia': 23, 'keratella_cochlearis': 24, 'keratella_quadrata': 25, 'leptodora': 26, 'maybe_cyano': 27, 'nauplius': 28, 'paradileptus': 29, 'polyarthra': 30, 'rotifers': 31, 'synchaeta': 32, 'trichocerca': 33, 'unknown': 34, 'unknown_plankton': 35, 'uroglena': 36}\n",
      "2024-12-20 12:27:22,611 - root - INFO - Classes to keep based on defined priority classes, if emtpy no prio are set:[] \n",
      "             Classes to keep based on defined rest classes. If empty, no class are filtered out: []\n",
      "2024-12-20 12:27:22,611 - lit_ecology_classifier.splitting.split_processor - INFO - Class map generated: {'aphanizomenon': 1, 'asplanchna': 2, 'asterionella': 3, 'bosmina': 4, 'brachionus': 5, 'ceratium': 6, 'chaoborus': 7, 'collotheca': 8, 'conochilus': 9, 'copepod_skins': 10, 'cyclops': 11, 'daphnia': 12, 'daphnia_skins': 13, 'diaphanosoma': 14, 'diatom_chain': 15, 'dinobryon': 16, 'dirt': 17, 'eudiaptomus': 18, 'filament': 19, 'fish': 20, 'fragilaria': 21, 'hydra': 22, 'kellicottia': 23, 'keratella_cochlearis': 24, 'keratella_quadrata': 25, 'leptodora': 26, 'maybe_cyano': 27, 'nauplius': 28, 'paradileptus': 29, 'polyarthra': 30, 'rotifers': 31, 'synchaeta': 32, 'trichocerca': 33, 'unknown': 34, 'unknown_plankton': 35, 'uroglena': 36}\n"
     ]
    }
   ],
   "source": [
    "split_processor = SplitProcessor(split_strategy= ExampleSplitProcessor(),\n",
    "                                 filter_strategy= 'PlanktonFilter',\n",
    "                                 split_overview = split_overview, \n",
    "                                 image_overview= \"data\\interim\\overview.csv\",\n",
    "                                 filter_args= {\"dataset_version\":\"2\"})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_version</th>\n",
       "      <th>OOD</th>\n",
       "      <th>split_strategy</th>\n",
       "      <th>filter_strategy</th>\n",
       "      <th>combined_split_hash</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...</td>\n",
       "      <td>Split used for Deep Learning Classification of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OOD_2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>PlanktonFilter</td>\n",
       "      <td>7ac1342e84ca156574ef657e342945eeee398dc01c0563...</td>\n",
       "      <td>Split used for Producing Plankton Classifiers ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_version     OOD split_strategy filter_strategy  \\\n",
       "0               1                Unknown  PlanktonFilter   \n",
       "1               2   OOD_2        Unknown  PlanktonFilter   \n",
       "\n",
       "                                 combined_split_hash  \\\n",
       "0  7ae8bedcd1f7b93380ada9d97df367f75e4ff22c0f9214...   \n",
       "1  7ac1342e84ca156574ef657e342945eeee398dc01c0563...   \n",
       "\n",
       "                                         description  \n",
       "0  Split used for Deep Learning Classification of...  \n",
       "1  Split used for Producing Plankton Classifiers ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(split_processor, \"split_overview_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.splitting.split_processor - DEBUG - Class name: PlanktonFilter\n",
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.splitting.split_processor - DEBUG - Class name: Stratified\n",
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.splitting.split_processor - INFO - No existing split found, creating a new split.\n",
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.splitting.split_processor - INFO - Creating a new split based on the given split and filter strategy.:<class 'pandas.core.frame.DataFrame'>\n",
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.helpers.helpers - DEBUG - Importing the modul lit_ecology_classifier.splitting.filtering.PlanktonFilter\n",
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.helpers.filter - DEBUG - Filtering the dataframe based on the dataset versions: []\n",
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.helpers.filter - DEBUG - No dataset version provided, returning the original dataframe\n",
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.helpers.filter - DEBUG - No OOD defined, not filterig based on the OOD images.\n",
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.splitting.split_processor - INFO - Class map generated: {'aphanizomenon': 1, 'asplanchna': 2, 'asterionella': 3, 'bosmina': 4, 'brachionus': 5, 'ceratium': 6, 'chaoborus': 7, 'collotheca': 8, 'conochilus': 9, 'copepod_skins': 10, 'cyclops': 11, 'daphnia': 12, 'daphnia_skins': 13, 'diaphanosoma': 14, 'diatom_chain': 15, 'dinobryon': 16, 'dirt': 17, 'eudiaptomus': 18, 'filament': 19, 'fish': 20, 'fragilaria': 21, 'hydra': 22, 'kellicottia': 23, 'keratella_cochlearis': 24, 'keratella_quadrata': 25, 'leptodora': 26, 'maybe_cyano': 27, 'nauplius': 28, 'paradileptus': 29, 'polyarthra': 30, 'rotifers': 31, 'synchaeta': 32, 'trichocerca': 33, 'unknown': 34, 'unknown_plankton': 35, 'uroglena': 36}\n",
      "2024-12-20 12:27:22,671 - root - INFO - Classes to keep based on defined priority classes, if emtpy no prio are set:[] \n",
      "             Classes to keep based on defined rest classes. If empty, no class are filtered out: []\n",
      "2024-12-20 12:27:22,671 - lit_ecology_classifier.splitting.split_processor - INFO - Class map generated: {'aphanizomenon': 1, 'asplanchna': 2, 'asterionella': 3, 'bosmina': 4, 'brachionus': 5, 'ceratium': 6, 'chaoborus': 7, 'collotheca': 8, 'conochilus': 9, 'copepod_skins': 10, 'cyclops': 11, 'daphnia': 12, 'daphnia_skins': 13, 'diaphanosoma': 14, 'diatom_chain': 15, 'dinobryon': 16, 'dirt': 17, 'eudiaptomus': 18, 'filament': 19, 'fish': 20, 'fragilaria': 21, 'hydra': 22, 'kellicottia': 23, 'keratella_cochlearis': 24, 'keratella_quadrata': 25, 'leptodora': 26, 'maybe_cyano': 27, 'nauplius': 28, 'paradileptus': 29, 'polyarthra': 30, 'rotifers': 31, 'synchaeta': 32, 'trichocerca': 33, 'unknown': 34, 'unknown_plankton': 35, 'uroglena': 36}\n",
      "2024-12-20 12:27:22,685 - lit_ecology_classifier.helpers.helpers - DEBUG - Importing the modul lit_ecology_classifier.splitting.split_strategies.Stratified\n",
      "2024-12-20 12:27:22,685 - lit_ecology_classifier.splitting.split_strategies.stratified - INFO - Performing stratified split. Shape of data:(39162, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "      <th>sha256</th>\n",
       "      <th>date</th>\n",
       "      <th>OOD_v2</th>\n",
       "      <th>version_1</th>\n",
       "      <th>version_2</th>\n",
       "      <th>train_v1</th>\n",
       "      <th>test_v1</th>\n",
       "      <th>val_v1</th>\n",
       "      <th>train_v2</th>\n",
       "      <th>test_v2</th>\n",
       "      <th>val_v2</th>\n",
       "      <th>class_map_x</th>\n",
       "      <th>class_map_y</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1570543372901157-3725350526242-...</td>\n",
       "      <td>6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...</td>\n",
       "      <td>2019-10-08 14:02:52+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1570543374882008-3725352526408-...</td>\n",
       "      <td>09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...</td>\n",
       "      <td>2019-10-08 14:02:54+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1589472012505862-10217420880920...</td>\n",
       "      <td>1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...</td>\n",
       "      <td>2020-05-14 16:00:12+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1589472120505648-10217528889899...</td>\n",
       "      <td>f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...</td>\n",
       "      <td>2020-05-14 16:02:00+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aphanizomenon</td>\n",
       "      <td>SPC-EAWAG-0P5X-1589472215513831-10217623897796...</td>\n",
       "      <td>9cfb8f3f9d36cb50c32bedc72724092a7a01576ccb8529...</td>\n",
       "      <td>2020-05-14 16:03:35+00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39437</th>\n",
       "      <td>unknown_plankton</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628924603886864-33431897306214...</td>\n",
       "      <td>f37b8728341c8523cae1e78a3014c1b4aa0f4741553c67...</td>\n",
       "      <td>2021-08-14 07:03:23+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39438</th>\n",
       "      <td>unknown_plankton</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628946228440913-33453521474102...</td>\n",
       "      <td>e0753b2f321e28fb34885cb5b08e1107e943345ca014ce...</td>\n",
       "      <td>2021-08-14 13:03:48+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39439</th>\n",
       "      <td>unknown_plankton</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628953524258605-33460817200807...</td>\n",
       "      <td>b6060aca8743971e66fbcd835dbfaa3ccc7676ba02543d...</td>\n",
       "      <td>2021-08-14 15:05:24+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39440</th>\n",
       "      <td>unknown_plankton</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628960940234482-33468233086890...</td>\n",
       "      <td>f422c45d51225872818e04396413ce42ea2b391da13dd9...</td>\n",
       "      <td>2021-08-14 17:09:00+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39441</th>\n",
       "      <td>uroglena</td>\n",
       "      <td>SPC-EAWAG-0P5X-1628899698205785-33406991970972...</td>\n",
       "      <td>5ec2e22016e6e7c812b61beb997b81af92cf351d2fc180...</td>\n",
       "      <td>2021-08-14 00:08:18+00:00</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39442 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  class                                              image  \\\n",
       "0         aphanizomenon  SPC-EAWAG-0P5X-1570543372901157-3725350526242-...   \n",
       "1         aphanizomenon  SPC-EAWAG-0P5X-1570543374882008-3725352526408-...   \n",
       "2         aphanizomenon  SPC-EAWAG-0P5X-1589472012505862-10217420880920...   \n",
       "3         aphanizomenon  SPC-EAWAG-0P5X-1589472120505648-10217528889899...   \n",
       "4         aphanizomenon  SPC-EAWAG-0P5X-1589472215513831-10217623897796...   \n",
       "...                 ...                                                ...   \n",
       "39437  unknown_plankton  SPC-EAWAG-0P5X-1628924603886864-33431897306214...   \n",
       "39438  unknown_plankton  SPC-EAWAG-0P5X-1628946228440913-33453521474102...   \n",
       "39439  unknown_plankton  SPC-EAWAG-0P5X-1628953524258605-33460817200807...   \n",
       "39440  unknown_plankton  SPC-EAWAG-0P5X-1628960940234482-33468233086890...   \n",
       "39441          uroglena  SPC-EAWAG-0P5X-1628899698205785-33406991970972...   \n",
       "\n",
       "                                                  sha256  \\\n",
       "0      6fb0b3fa4b36614703ee1abdcf8efba4cd936982ca5fb6...   \n",
       "1      09e4aa12fdc992bbd840b7913f6f35394637bc2135c49f...   \n",
       "2      1ace5cdd5a68e8cd5fa703c92ac7c6e6b1d362b517132f...   \n",
       "3      f9a38d8538b1ac64383199851c61ad2f7f784e430086ea...   \n",
       "4      9cfb8f3f9d36cb50c32bedc72724092a7a01576ccb8529...   \n",
       "...                                                  ...   \n",
       "39437  f37b8728341c8523cae1e78a3014c1b4aa0f4741553c67...   \n",
       "39438  e0753b2f321e28fb34885cb5b08e1107e943345ca014ce...   \n",
       "39439  b6060aca8743971e66fbcd835dbfaa3ccc7676ba02543d...   \n",
       "39440  f422c45d51225872818e04396413ce42ea2b391da13dd9...   \n",
       "39441  5ec2e22016e6e7c812b61beb997b81af92cf351d2fc180...   \n",
       "\n",
       "                            date  OOD_v2  version_1  version_2  train_v1  \\\n",
       "0      2019-10-08 14:02:52+00:00   False       True       True      True   \n",
       "1      2019-10-08 14:02:54+00:00   False       True       True      True   \n",
       "2      2020-05-14 16:00:12+00:00   False       True       True      True   \n",
       "3      2020-05-14 16:02:00+00:00   False       True       True      True   \n",
       "4      2020-05-14 16:03:35+00:00   False       True       True     False   \n",
       "...                          ...     ...        ...        ...       ...   \n",
       "39437  2021-08-14 07:03:23+00:00    True      False       True     False   \n",
       "39438  2021-08-14 13:03:48+00:00    True      False       True     False   \n",
       "39439  2021-08-14 15:05:24+00:00    True      False       True     False   \n",
       "39440  2021-08-14 17:09:00+00:00    True      False       True     False   \n",
       "39441  2021-08-14 00:08:18+00:00    True      False       True     False   \n",
       "\n",
       "       test_v1  val_v1  train_v2  test_v2  val_v2  class_map_x  class_map_y  \\\n",
       "0        False   False      True    False   False            1            1   \n",
       "1        False   False     False     True   False            1            1   \n",
       "2        False   False      True    False   False            1            1   \n",
       "3        False   False      True    False   False            1            1   \n",
       "4        False    True      True    False   False            1            1   \n",
       "...        ...     ...       ...      ...     ...          ...          ...   \n",
       "39437    False   False     False    False   False           35           35   \n",
       "39438    False   False     False    False   False           35           35   \n",
       "39439    False   False     False    False   False           35           35   \n",
       "39440    False   False     False    False   False           35           35   \n",
       "39441    False   False     False    False   False           36           36   \n",
       "\n",
       "       split  \n",
       "0      train  \n",
       "1       test  \n",
       "2      train  \n",
       "3      train  \n",
       "4       test  \n",
       "...      ...  \n",
       "39437  train  \n",
       "39438  train  \n",
       "39439  train  \n",
       "39440  train  \n",
       "39441  train  \n",
       "\n",
       "[39442 rows x 16 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_processor.search_splits(filter_strategy= \"PlanktonFilter\", split_strategy= \"Stratified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
