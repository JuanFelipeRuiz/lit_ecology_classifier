<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Introduction to PyTorch Lightning &mdash; lit_ecology_classifier 0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=8dde47fa"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            lit_ecology_classifier
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Introduction to PyTorch Lightning</a><ul>
<li><a class="reference internal" href="#what-is-pytorch-lightning">What is PyTorch Lightning?</a></li>
<li><a class="reference internal" href="#key-features-of-pytorch-lightning">Key Features of PyTorch Lightning:</a></li>
<li><a class="reference internal" href="#why-use-pytorch-lightning">Why Use PyTorch Lightning?</a></li>
<li><a class="reference internal" href="#basic-components-of-pytorch-lightning">Basic Components of PyTorch Lightning</a></li>
<li><a class="reference internal" href="#how-to-extend-pytorch-lightning">How to Extend PyTorch Lightning</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">lit_ecology_classifier</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Introduction to PyTorch Lightning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/lightning_intro.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="introduction-to-pytorch-lightning">
<h1>Introduction to PyTorch Lightning<a class="headerlink" href="#introduction-to-pytorch-lightning" title="Link to this heading"></a></h1>
<p>PyTorch Lightning is a high-level framework built on top of PyTorch, designed to make deep learning research and experimentation faster, more flexible, and more reproducible. This guide will help you understand what PyTorch Lightning is, why it is beneficial, and how you can extend it for your own projects.</p>
<section id="what-is-pytorch-lightning">
<h2>What is PyTorch Lightning?<a class="headerlink" href="#what-is-pytorch-lightning" title="Link to this heading"></a></h2>
<p>PyTorch Lightning provides a standardized interface for training deep learning models. It abstracts away much of the boilerplate code needed for PyTorch, allowing you to focus on the actual research and model development. Lightning helps streamline tasks such as training loops, validation, checkpointing, logging, and multi-GPU training.</p>
</section>
<section id="key-features-of-pytorch-lightning">
<h2>Key Features of PyTorch Lightning:<a class="headerlink" href="#key-features-of-pytorch-lightning" title="Link to this heading"></a></h2>
<ul class="simple">
<li><p><strong>Standardized Structure</strong>: Enforces a clean separation of model, data, and training code.</p></li>
<li><p><strong>Automatic Checkpointing</strong>: Saves model weights and other important information during training.</p></li>
<li><p><strong>Logging</strong>: Easily log metrics and visualize them using tools like TensorBoard.</p></li>
<li><p><strong>Scalability</strong>: Seamlessly scale your models to multiple GPUs or nodes with minimal code changes.</p></li>
<li><p><strong>Flexibility</strong>: Compatible with other PyTorch utilities and custom research code.</p></li>
</ul>
</section>
<section id="why-use-pytorch-lightning">
<h2>Why Use PyTorch Lightning?<a class="headerlink" href="#why-use-pytorch-lightning" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p><strong>Ease of Use</strong>: Simplifies complex training and validation loops, making your code more readable and maintainable.</p></li>
<li><p><strong>Reproducibility</strong>: Standardized structure and logging make it easier to reproduce experiments and results.</p></li>
<li><p><strong>Scalability</strong>: Built-in support for multi-GPU and distributed training allows you to scale up your experiments without rewriting your code.</p></li>
<li><p><strong>Focus on Research</strong>: By abstracting away boilerplate code, Lightning allows you to focus more on the research and less on the implementation details.</p></li>
</ol>
</section>
<section id="basic-components-of-pytorch-lightning">
<h2>Basic Components of PyTorch Lightning<a class="headerlink" href="#basic-components-of-pytorch-lightning" title="Link to this heading"></a></h2>
<ol class="arabic">
<li><p><strong>LightningModule</strong>: This is where you define your model architecture, training, validation, and test steps.</p>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>import pytorch_lightning as pl
import torch
from torch import nn
from torch.optim import Adam</p>
<dl class="simple">
<dt>class LitModel(pl.LightningModule):</dt><dd><dl class="simple">
<dt>def __init__(self):</dt><dd><p>super(LitModel, self).__init__()
self.layer = nn.Linear(28 * 28, 10)</p>
</dd>
<dt>def forward(self, x):</dt><dd><p>return self.layer(x.view(x.size(0), -1))</p>
</dd>
<dt>def training_step(self, batch, batch_idx):</dt><dd><p>x, y = batch
y_hat = self(x)
loss = nn.functional.cross_entropy(y_hat, y)
return loss</p>
</dd>
<dt>def configure_optimizers(self):</dt><dd><p>return Adam(self.parameters(), lr=1e-3)</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><strong>LightningDataModule</strong>: This is where you define your data loading and preprocessing logic. Here is an example of a <cite>TarImageDataset</cite> used within a <cite>LightningDataModule</cite>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pytorch_lightning</span> <span class="k">as</span> <span class="nn">pl</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">lit_ecology_classifier.data.datamodule</span> <span class="kn">import</span> <span class="n">TarImageDataset</span>

<span class="k">class</span> <span class="nc">TarImageDataModule</span><span class="p">(</span><span class="n">pl</span><span class="o">.</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tar_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">class_map_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">priority_classes</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">TTA</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tar_path</span> <span class="o">=</span> <span class="n">tar_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">class_map_path</span> <span class="o">=</span> <span class="n">class_map_path</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">priority_classes</span> <span class="o">=</span> <span class="n">priority_classes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">TTA</span> <span class="o">=</span> <span class="n">TTA</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TarImageDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tar_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_map_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">priority_classes</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">TTA</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">TTA</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span> <span class="o">=</span> <span class="n">TarImageDataset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tar_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">class_map_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">priority_classes</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">TTA</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">TTA</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">val_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
</pre></div>
</div>
</li>
</ol>
</section>
<section id="how-to-extend-pytorch-lightning">
<h2>How to Extend PyTorch Lightning<a class="headerlink" href="#how-to-extend-pytorch-lightning" title="Link to this heading"></a></h2>
<ol class="arabic">
<li><p><strong>Custom Metrics</strong>: You can define custom metrics for your training and validation steps by integrating with libraries like <cite>torchmetrics</cite>.</p>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>from torchmetrics import Accuracy</p>
<dl class="simple">
<dt>class LitModel(pl.LightningModule):</dt><dd><dl class="simple">
<dt>def __init__(self):</dt><dd><p>super(LitModel, self).__init__()
self.layer = nn.Linear(28 * 28, 10)
self.accuracy = Accuracy()</p>
</dd>
<dt>def training_step(self, batch, batch_idx):</dt><dd><p>x, y = batch
y_hat = self(x)
loss = nn.functional.cross_entropy(y_hat, y)
acc = self.accuracy(y_hat, y)
self.log(‘train_acc’, acc, on_step=True, on_epoch=True, prog_bar=True)
return loss</p>
</dd>
</dl>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><strong>Custom Callbacks</strong>: You can add custom callbacks to your training process to extend its functionality.</p>
<p>Example:
.. code-block:: python</p>
<blockquote>
<div><p>from pytorch_lightning.callbacks import Callback</p>
<dl class="simple">
<dt>class CustomCallback(Callback):</dt><dd><dl class="simple">
<dt>def on_train_start(self, trainer, pl_module):</dt><dd><p>print(“Training is starting!”)</p>
</dd>
</dl>
</dd>
</dl>
<p>trainer = pl.Trainer(callbacks=[CustomCallback()])</p>
</div></blockquote>
</li>
</ol>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading"></a></h2>
<p>PyTorch Lightning is a powerful tool that can simplify your deep learning workflows, improve reproducibility, and allow you to scale your experiments with minimal effort. By using Lightning, you can focus more on your research and less on the boilerplate code.</p>
<p>For more information, visit the <a class="reference external" href="https://pytorch-lightning.readthedocs.io/en/latest/">PyTorch Lightning Documentation</a>.</p>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Benno Kaech.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>